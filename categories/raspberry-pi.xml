<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0"><channel><title>Kyle M. Douglass (Posts about raspberry pi)</title><link>http://kmdouglass.github.io/</link><description></description><atom:link href="http://kmdouglass.github.io/categories/raspberry-pi.xml" type="application/rss+xml" rel="self"></atom:link><language>en</language><lastBuildDate>Sun, 29 Apr 2018 10:11:13 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>How I built a cross-compilation workflow for the Raspberry Pi</title><link>http://kmdouglass.github.io/posts/how-i-built-a-cross-compilation-workflow-for-the-raspberry-pi.html</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;div&gt;&lt;p&gt;Some of you may know I tinker with the Raspberry Pi in my free time
and that one of my current projects is to build a lensless microscope
with the Pi as the brains. To control the microscope, I decided a
while ago that I would use &lt;a class="reference external" href="https://micro-manager.org/wiki/Micro-Manager"&gt;Micro-Manager&lt;/a&gt;, an open-source
software package for microscope control. I made this decision for a
few reasons:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;I already knew the Micro-Manager codebase since I use it frequently
at work.&lt;/li&gt;
&lt;li&gt;The Micro-Manager core provides a device-independent interface to
hardware.&lt;/li&gt;
&lt;li&gt;I've contributed to the project in the past and feel a sense of
loyalty to the project and the people involved. Expanding
Micro-Manager into embedded microscopy would be a great way for me
to give back to the community.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Building Micro-Manager from source code presents its own set of
challenges. After ensuring that you have the correct build
environment, you need to actually compile it, and here's where things
get tricky in Raspyberry Pi development. The Pi has an ARM processor,
whereas most laptops and workstations use a x86_64 processor. This
means that code compiled on a typical desktop PC will not work on the
Pi. As I showed in &lt;a class="reference external" href="https://kmdouglass.github.io/posts/micro-manager-on-the-raspberry-pi.html"&gt;my earlier post&lt;/a&gt;,
you can compile the code directly on the Pi to circumvent this, but
this unfortunately is quite cumbersome because the code base and
dependencies are quite large. (They are nearly 8 GB in
total). Furthermore, compiling the project on the Pi is slow and
requires connecting to it via ssh or working directly on a TV screen
or monitor.&lt;/p&gt;
&lt;p&gt;These problems extend beyond Micro-Manager to other large-scale
projects that require code compilation for a specific processor
architecture. In this post, I'll describe the workflow that I
developed for cross-compiling projects for the Raspberry Pi.&lt;/p&gt;
&lt;div class="section" id="previous-attempts"&gt;
&lt;h2&gt;Previous attempts&lt;/h2&gt;
&lt;p&gt;Prior to the workflow that is the main topic of this post, I managed
to cross-compile Micro-Manager using a &lt;cite&gt;chroot&lt;/cite&gt; environment and the
&lt;a class="reference external" href="https://www.qemu.org/"&gt;QEMU emulator&lt;/a&gt;. &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Chroot"&gt;chroot&lt;/a&gt; is a Linux command that
changes the apparent root (or '/') directory for a running
process. With this approach, I mount an image of the &lt;a class="reference external" href="https://www.raspberrypi.org/downloads/raspbian/"&gt;Raspbian
operating system&lt;/a&gt;
that contains the gcc and g++ compilers and libraries for the ARM
architecture. Then, I chroot into the image and run a setup script
that builds the software. During execution of this script, the QEMU
static libraries run the ARM compilers from within the chroot
environment to build the project. The compiled code remains inside the
image, which I then burn onto a micro SD card to insert into the Pi. I
uploaded &lt;a class="reference external" href="https://gist.github.com/kmdouglass/38e1383c7e62745f3cf522702c21cb49"&gt;a gist of the bash script&lt;/a&gt;
which orchestrates all this, and my inspiration for this approach came
from a great series of blog posts from &lt;a class="reference external" href="https://disconnected.systems/blog/custom-rpi-image-with-github-travis/"&gt;Disconnected Systems&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ultimately this approach is a huge amount of work. As you can see in
the gist, it's fairly complicated bash scripting that's not easy to
debug. Furthermore, the setup script that is run inside the image
needs to do a lot of work beyond cross-compiling, like setting up the
user, permissions, network, etc. Debugging the final product is also a
challenge because you need to verify that it's working on the Pi,
which requires burning the image to a micro SD card.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="cross-compiling-with-docker"&gt;
&lt;h2&gt;Cross-compiling with Docker&lt;/h2&gt;
&lt;p&gt;After a bit of research I decided I would try instead to use &lt;a class="reference external" href="https://www.docker.com/"&gt;Docker&lt;/a&gt; for cross-compilation and deployment to
the Pi. I had just started using Docker at work to build reproducible
environments for scientific computing research. In particular, and
unlike my chroot script, I had learned that a Docker container that
built the project could work on nearly any system that had Docker
installed. Furthermore, deploying updates can be done on any Raspberry
Pi that's running Docker.&lt;/p&gt;
&lt;p&gt;I liked the idea of a portable cross-compilation workflow, so I dove
into the Docker documentation and managed to get everything working in
a few weeks of tinkering at home.&lt;/p&gt;
&lt;div class="section" id="an-overview-of-docker"&gt;
&lt;h3&gt;An overview of Docker&lt;/h3&gt;
&lt;p&gt;You can find many resources online about Docker, so I won't go into
the details here. The main thing you need to know is that Docker is a
system for creating, running, and sharing &lt;em&gt;containers&lt;/em&gt;, which are
something like light weight virtual machines. Containers solve the
problem in software development of how to build and deploy programs
that have a complex set of dependencies. It does this by isolating the
environment in which a program runs from the rest of the operating
system. For example, if you have a computer that has a certain version
of gcc (the GNU C compiler) installed, but your application requires a
different version, then you can install the required gcc along with
your application inside a container and they will not interfere with
the version of gcc that belongs to your operating system. This also
means that you can send your container to any machine that has Docker
installed and it should just run without having to do any setup.&lt;/p&gt;
&lt;p&gt;Other important things to know about Docker are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;There are two main types of objects: images and containers. Images
are sort of like blueprints that define what is inside a container,
whereas containers are like the actual buildings specified by the
blueprints. There can be many containers that come from a single
image.&lt;/li&gt;
&lt;li&gt;Containers are meant to be immutable. When you stop them and restart
them, they always restart in the same state as when they were first
created.&lt;/li&gt;
&lt;li&gt;Since containers are immutable, some of your application data may
need to be placed in a volume, which is either another container or
a folder on the host system. A volume gets connected to your
application container and exists even when your application
container is not running.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="the-cross-compilation-workflow"&gt;
&lt;h2&gt;The cross-compilation workflow&lt;/h2&gt;
&lt;p&gt;Now that we have established the essential background to this project,
let's look at the cross-compilation workflow. Below is a picture that
provides a sense of the entire process, moving in general from
left-to-right.&lt;/p&gt;
&lt;img alt="The cross-compilation workflow" class="align-center" src="http://kmdouglass.github.io/mm_docker_workflow.png"&gt;
&lt;p&gt;The process involves two Docker containers: one for building
Micro-Manager and the other for running the application. The build
dependencies and the QEMU emulator are both located inside the build
container, having been specified when its image was created. These
allow us to compile Micro-Manager for the ARM architecture.  The
source code is connected to the build container as a &lt;em&gt;bind mount&lt;/em&gt;,
which is a folder from the host workstation that is mounted inside the
build container when it is run.&lt;/p&gt;
&lt;p&gt;Once the libraries are compiled, they are installed into a folder
inside the bind mount so that the host system will have access to them
after the build container closes. Next, the compiled libraries are
copied directly into an image that defines the application
container. This image defines only the essential run-time requirements
for running Micro-Manager and nothing else. The application image is
stored on the registry server which I set up on my local network. This
makes it easy for the Raspberry Pi to download the latest image and
run the Micro-Manager application container whenever I make changes.&lt;/p&gt;
&lt;p&gt;An important aspect of this workflow is how the data is passed between
the systems and containers. Unlike what you will find in many
introductory tutorials on Docker, I do not add the Micro-Manager
source code directly to the build image/containers but instead use a
bind mount. The reason for this is that the source code and 3rd party
libraries are quite large, about 8 GB in total. By using a bind mount,
I avoid needless copying of this data. Another reason for using a bind
mount is that the source code will change frequently during
development. If I add the source code to the image, then I will have
to recreate the image every time the source code changes.&lt;/p&gt;
&lt;p&gt;Once the libraries are built, I directly copy them into the
application image because they are much, much smaller than the source
code. I also want the code stored directly in the image so that the
application image is all the Raspberry Pi needs to run the
program. The image is stored in my local &lt;a class="reference external" href="https://docs.docker.com/registry/"&gt;Docker registry&lt;/a&gt; server so that once I push an
updated image to the server, the Raspberry Pi can download it and use
it immediately.&lt;/p&gt;
&lt;div class="section" id="step-0-prerequisites"&gt;
&lt;h3&gt;Step 0: Prerequisites&lt;/h3&gt;
&lt;p&gt;I am going to assume that you already have installed Docker. (If not,
follow &lt;a class="reference external" href="https://docs.docker.com/install/"&gt;these directions&lt;/a&gt;.) I am
also going to assume that you are somewhat familiar with how to work
on a Linux system. The Raspberry Pi runs Linux, so you probably
wouldn't be here if you didn't already know at least a little.&lt;/p&gt;
&lt;p&gt;For this article, I am working with these versions of Docker and
Ubuntu on my host workstation.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
kmdouglass@xxxxx:~$ uname -a
Linux xxxxx 4.13.0-39-generic #44~16.04.1-Ubuntu SMP Thu Apr 5 16:43:10 UTC 2018 x86_64 x86_64
x86_64 GNU/Linux

kmdouglass@xxxxx:~$ docker version
Client:
 Version:      18.03.1-ce
 API version:  1.37
 Go version:   go1.9.5
 Git commit:   9ee9f40
 Built:        Thu Apr 26 07:17:20 2018
 OS/Arch:      linux/amd64
 Experimental: false
 Orchestrator: swarm

Server:
 Engine:
  Version:      18.03.1-ce
  API version:  1.37 (minimum version 1.12)
  Go version:   go1.9.5
  Git commit:   9ee9f40
  Built:        Thu Apr 26 07:15:30 2018
  OS/Arch:      linux/amd64
  Experimental: false
&lt;/pre&gt;
&lt;p&gt;Finally, below is how my project directory structure is laid out.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
kmdouglass@xxxxx:~/src/alphapi/docker$ tree -L 2
.
└── rpi-micromanager
    ├── 2.0-python
    │   ├── build
    │   └── Dockerfile
    └── build
        ├── build
        ├── Dockerfile
        ├── run
        └── setup
&lt;/pre&gt;
&lt;p&gt;I have two folders; build, which contains the files for the build
container, and 2.0-python, which contains the files for creating the
Micro-Manager application container. (In my case, I am going to build
the Python wrapper for Micro-Manager 2.0.) Inside each folder are the
scripts and Dockerfiles that execute the various steps of the
workflow.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="step-1-create-the-build-image"&gt;
&lt;h3&gt;Step 1: Create the build image&lt;/h3&gt;
&lt;p&gt;Inside the build folder, I have a file called Dockerfile. Here are its
contents:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# Copyright (C) 2018 Kyle M. Douglass
#
# Defines a build environment for Micro-Manager on the Raspberry Pi.
#
# Usage: docker build \
#          -t NAME:TAG \
#          .
#

FROM resin/raspberrypi3-debian:stretch
MAINTAINER Kyle M. Douglass &amp;lt;kyle.m.douglass@gmail.com&amp;gt;

RUN [ "cross-build-start" ]

# Get the build dependencies.
RUN apt-get update &amp;amp;&amp;amp; apt-get -y install --no-install-recommends \
autoconf \
automake \
build-essential \
git \
libatlas-base-dev \
libboost-dev \
libboost-all-dev \
libtool \
patch \
pkg-config \
python3-dev \
python3-pip \
python3-setuptools \
python3-wheel \
swig \
&amp;amp;&amp;amp; apt-get clean &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/* \
&amp;amp;&amp;amp; pip3 install numpy

RUN [ "cross-build-end" ]

# Set up the mount point for the source files and setup script.
ADD setup /micro-manager/
VOLUME /micro-manager/src

WORKDIR /micro-manager/src
ENTRYPOINT [ "/sbin/tini", "-s", "--" ]
CMD [ "/micro-manager/setup" ]
&lt;/pre&gt;
&lt;p&gt;A Dockerfile defines the steps in building an image -- in this case,
the build image. Let's break this file down into pieces. In the first
two lines that follow the comments, I specify that my image is based
on the resin/raspberrypi3-debian:stretch image and that I am the
maintainer.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
FROM resin/raspberrypi3-debian:stretch
MAINTAINER Kyle M. Douglass &amp;lt;kyle.m.douglass@gmail.com&amp;gt;
&lt;/pre&gt;
&lt;p&gt;Images from &lt;a class="reference external" href="https://hub.docker.com/u/resin/"&gt;Resin&lt;/a&gt; are freely
available and already have the QEMU emulator installed. Next, I
specify what commands should be run for the ARM architecture. Any
commands located between &lt;tt class="docutils literal"&gt;RUN [ &lt;span class="pre"&gt;"cross-build-start"&lt;/span&gt; ]&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;RUN [
&lt;span class="pre"&gt;"cross-build-end"&lt;/span&gt; ]&lt;/tt&gt; will be run using the emulator. Inside these two
commands, I install the build dependencies for Micro-Manager using
&lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;apt-get&lt;/span&gt;&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;pip&lt;/tt&gt;. (These are just standard commands for
installing software on Debian/Ubuntu Linux machines and from PyPI,
respectively.)&lt;/p&gt;
&lt;p&gt;After the installation of the requirements completes, I add the setup
script to the folder /micro-manager inside the image with the &lt;tt class="docutils literal"&gt;ADD
setup &lt;span class="pre"&gt;/micro-manager/&lt;/span&gt;&lt;/tt&gt; command. The setup script contains the
commands that will actually compile Micro-Manager. I then define a
mount point for the source code with &lt;tt class="docutils literal"&gt;VOLUME
&lt;span class="pre"&gt;/micro-manager/src&lt;/span&gt;&lt;/tt&gt;. &lt;strong&gt;It's important to realize here that you do not
mount volumes inside images, you mount volumes inside containers.&lt;/strong&gt;
This command is just telling the image to expect a folder to be
mounted at this location when the container is run.&lt;/p&gt;
&lt;p&gt;The last three lines set the working directory, the entrypoint and the
default container command, respectively.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
WORKDIR /micro-manager/src
ENTRYPOINT [ "/sbin/tini", "-s", "--" ]
CMD [ "/micro-manager/setup" ]
&lt;/pre&gt;
&lt;p&gt;This specific entrypoint tells Docker that any containers built from
this image should first run Tini, which is a lightweight init system
for Docker containers. If you do not specify Tini as the entry point,
then it will not be able to reap zombies. (I don't know what this
means exactly, but it sounds cool and you can read about it here:
&lt;a class="reference external" href="https://github.com/krallin/tini"&gt;https://github.com/krallin/tini&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;By default, the container will run the setup script, but, since I used
the &lt;tt class="docutils literal"&gt;CMD&lt;/tt&gt; directive, this can be overriden in case we need to
perform some manual steps. Roughly speaking, you can think of the
entrypoint as the command that can not be overridden and the CMD
command as the one that can be. In other words, Tini will always be
executed when containers created from this image are launched, whereas
you can choose not to run the setup script but instead to enter the
container through a Bash shell, for example.&lt;/p&gt;
&lt;p&gt;To build the image, I use the following build script located in the
same directory as the Dockerfile for convenience:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#!/bin/bash
# Copyright (C) 2018 Kyle M. Douglass
#
# Usage: ./build
#

docker build \
       -t localhost:5000/rpi-micromanager:build \
       .
&lt;/pre&gt;
&lt;p&gt;By using &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;-t&lt;/span&gt; &lt;span class="pre"&gt;localhost:5000/rpi-micromanager:build&lt;/span&gt;&lt;/tt&gt; argument I am
giving the image a name of &lt;em&gt;rpi-micromanager&lt;/em&gt;, a tag of &lt;em&gt;build&lt;/em&gt;, and
specifying that I will eventually host this image on my local registry
server (localhost) on port 5000.&lt;/p&gt;
&lt;p&gt;In case you are wondering about the contents of the setup script,
don't worry. I'll explain it in the next section.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="step-2-compile-micro-manager"&gt;
&lt;h3&gt;Step 2: Compile Micro-Manager&lt;/h3&gt;
&lt;p&gt;After the image is built, I create a container and use it to compile
Micro-Manager. For this, I use the run script in the build directory:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#!/bin/bash
# Copyright (C) 2018 Kyle M. Douglass
#
# Usage: ./run DIR CONFIGURE
#
# DIR is the parent folder containing the micro-manager Git
# repository, the 3rdpartypublic Subversion repository, and any
# additional build resources.
#
# If CONFIGURE=true, the build system is remade and the configure
# script is rerun before running 'make' and 'make install'. If
# CONFIGURE=false, only 'make' and 'make install' are run.
#
# The compiled program files are stored in a bind mount volume so that
# they may be copied into the deployment container.
#

src_dir=$1
cmd="/micro-manager/setup $2"

# Remove the build artifacts from previous builds.
if [ "$2" == true ] || [ "$2" == false ]; then
    rm -rf ${src_dir}/build || true
fi

docker run --rm \
       -v ${src_dir}:/micro-manager/src \
       --name mm-build \
       localhost:5000/rpi-micromanager:build \
       ${cmd}
&lt;/pre&gt;
&lt;p&gt;The script takes two arguments. The first is the path to the folder
containing all the source code (see below for details). The second
argument is either &lt;strong&gt;true&lt;/strong&gt; or &lt;strong&gt;false&lt;/strong&gt;. (It can actually be
anything, but it will only compile Micro-Manager if either &lt;strong&gt;true&lt;/strong&gt; or
&lt;strong&gt;false&lt;/strong&gt; are provided.) If true, the full build process is run,
including setting up the configure script; if false, only make and
make install are run, which should recompile and install only recently
updated files.&lt;/p&gt;
&lt;p&gt;The run script uses the -v argument to &lt;tt class="docutils literal"&gt;docker run&lt;/tt&gt; to mount the
source directory into the container at the point specified by the
&lt;tt class="docutils literal"&gt;VOLUME&lt;/tt&gt; command in the Dockerfile. The directory layout on my host
file system for the source directory looks like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
kmdouglass@xxxxx:/media/kmdouglass/Data/micro-manager$ tree -L 1
.
├── 3rdpartypublic
├── micro-manager
└── patches
&lt;/pre&gt;
&lt;p&gt;The patches folder is not necessary and only there to fix &lt;a class="reference external" href="https://github.com/micro-manager/micro-manager/pull/613"&gt;a bug&lt;/a&gt; in the
WieneckeSinscke device adapter. (This bug may be fixed by now.)
3rdpartypublic is the large Subversion repository of all the required
software to build Micro-Manager, and micro-manager is the &lt;a class="reference external" href="https://github.com/micro-manager/micro-manager"&gt;cloned
GitHub repository&lt;/a&gt;. Prior to building,
I checkout the mm2 branch because I am interested in developing my
application for Micro-Manager 2.0.&lt;/p&gt;
&lt;p&gt;The setup script that is run inside the container and mentioned in the
previous section looks like this:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#!/bin/bash
#
# # Copyright (C) 2018 Kyle M. Douglass
#
# Builds Micro-Manager.
#
# Usage: ./setup CONFIGURE
#
# If CONFIGURE=true, the build system is remade and the configure
# script is rerun before running 'make' and 'make install'. If
# CONFIGURE=false, only 'make' and 'make install' or run.
#
# Kyle M. Douglass, 2018
#

# Move into the source directory.
cd micro-manager

# Undo any previous patches.
git checkout -- DeviceAdapters/WieneckeSinske/CAN29.cpp
git checkout -- DeviceAdapters/WieneckeSinske/WieneckeSinske.cpp

# Patch the broken WieneckeSinske device adapter.
patch DeviceAdapters/WieneckeSinske/CAN29.cpp &amp;lt; ../patches/CAN29.cpp.diff \
&amp;amp;&amp;amp; patch DeviceAdapters/WieneckeSinske/WieneckeSinske.cpp &amp;lt; ../patches/WieneckeSinske.cpp.diff

# Compile MM2.
if [ "$1" = true ]; then
    # Remake the entire build system, then compile from scratch.
    ./autogen.sh
    PYTHON="/usr/bin/python3" ./configure \
        --prefix="/micro-manager/src/build" \
        --with-python="/usr/include/python3.5" \
        --with-boost-libdir="/usr/lib/arm-linux-gnueabihf" \
        --with-boost="/usr/include/boost" \
        --disable-java-app \
        --disable-install-dependency-jars \
        --with-java="no"
    make
    make install
    chmod -R a+w /micro-manager/src/build
elif [ "$1" = false ]; then
    # Only recompile changed source files.
    make
    make install
    chmod -R a+w /micro-manager/src/build
else
    echo "$1 : Unrecognized argument."
    echo "Pass \"true\" to run the full build process."
    echo "Pass \"false\" to run only \"make\" and \"make install\"."
fi
&lt;/pre&gt;
&lt;p&gt;Most important in this script is the call to &lt;tt class="docutils literal"&gt;configure&lt;/tt&gt;. You can
see that the compiled libraries and Python wrapper will be written to
the build folder inside the mounted directory. This gives the host
file system access to the compiled artifacts after the container has
stopped.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="step-3-build-the-application-image"&gt;
&lt;h3&gt;Step 3: Build the application image&lt;/h3&gt;
&lt;p&gt;Once the libraries are compiled, we can add them to an application
image that contains only the essentials for running Micro-Manager.&lt;/p&gt;
&lt;p&gt;For this, I use a separate Dockerfile inside the 2.0-python
directory:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# Copyright (C) 2018 Kyle M. Douglass
#
# Builds the Micro-Manager 2.0 Python wrapper for the Raspberry Pi.
#
# Usage: docker build \
#          -t NAME:TAG \
#          .
#

FROM resin/raspberrypi3-debian:stretch
MAINTAINER Kyle M. Douglass &amp;lt;kyle.m.douglass@gmail.com&amp;gt;

RUN [ "cross-build-start" ]

# Install the run-time dependencies.
RUN apt-get update &amp;amp;&amp;amp; apt-get -y install --no-install-recommends \
    libatlas-base-dev \
    libboost-all-dev \
    python3-pip \
    python3-setuptools \
    python3-wheel \
    &amp;amp;&amp;amp; pip3 install numpy \
    &amp;amp;&amp;amp; apt-get clean &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/*

# Copy in the Micro-Manager source files.
RUN useradd -ms /bin/bash micro-manager
WORKDIR /home/micro-manager/app
COPY --chown=micro-manager:micro-manager . .

RUN [ "cross-build-end" ]

# Final environment configuration.
USER micro-manager:micro-manager
ENV PYTHONPATH /home/micro-manager/app/lib/micro-manager
ENTRYPOINT ["/sbin/tini", "-s", "--"]
CMD ["/usr/bin/python3"]
&lt;/pre&gt;
&lt;p&gt;As before, I use a clean resin base image. However, this time I only
install the essential software to run Micro-Manager.&lt;/p&gt;
&lt;p&gt;After apt-getting and pip-installing everything, I create a new user
called &lt;strong&gt;micro-manager&lt;/strong&gt; and a new folder called &lt;strong&gt;app&lt;/strong&gt; inside this
user's home directory:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# Copy in the Micro-Manager source files.
RUN useradd -ms /bin/bash micro-manager
WORKDIR /home/micro-manager/app
&lt;/pre&gt;
&lt;p&gt;Next, I directly copy the compiled libraries into the image with the
COPY command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
COPY --chown=micro-manager:micro-manager . .
&lt;/pre&gt;
&lt;p&gt;The two periods (.) mean that I copy the current host directory's
contents into the container's current working directory
(/home/micro-manager/app). What is the current host directory? Well,
as I explain below, I actually run this Dockerfile from inside the
&lt;strong&gt;build&lt;/strong&gt; folder that was created to hold the compiled libraries in
the previous step. But first, I'll end my explanation of the
Dockerfile by saying that I switch the USER so that I do not run the
container as root, add the library to the PYTHONPATH environment
variable, and setup the default command as the python3 interpreter.&lt;/p&gt;
&lt;p&gt;To build this image, I use the following build script:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#!/bin/bash
# Copyright (C) 2018 Kyle M. Douglass
#
# Usage: ./build DIR
#
# DIR is the root directory containing the Micro-Manager build
# artifacts. These artifacts will be added to the Docker image.
#

src_dir=$1

cp Dockerfile ${src_dir}
cd ${src_dir}

docker build \
       -t localhost:5000/rpi-micromanager:2.0-python \
       .
&lt;/pre&gt;
&lt;p&gt;This script takes one argument, which is the &lt;strong&gt;build&lt;/strong&gt; directory
containing the compiled source code. The script first copies the
Dockerfile into this directory and then changes into it with the cd
command. (This explains the two periods (.) in the COPY command in the
Dockerfile.)&lt;/p&gt;
&lt;p&gt;Finally, I build the image and give it a name of
localhost:5000/rpi-micromanager:2.0-python.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="step-4-add-the-image-to-the-local-registry-server"&gt;
&lt;h3&gt;Step 4: Add the image to the local registry server&lt;/h3&gt;
&lt;p&gt;Now we need a way to get the image from the workstation onto the
Raspberry Pi. Of course, I could manually transfer the file with a USB
stick or possibly use ssh, but what if I have multiple Pi's? This
process could become cumbersome. Docker provides a few ways to push
and pull images across a network. The most obvious is &lt;a class="reference external" href="https://hub.docker.com/"&gt;Dockerhub&lt;/a&gt;, a site for freely sharing images. For the
moment I don't want to use Dockerhub, though, because I have not yet
checked all the software licenses and am unsure as to what my rights
are for putting an image with Micro-Manager software on a public
repository.&lt;/p&gt;
&lt;p&gt;A better option, especially for testing, is to use a local registry
server. This server operates only on my home network and already
allows my workstation and Pi's to communicate with one
another. Following the &lt;a class="reference external" href="https://docs.docker.com/registry/deploying/"&gt;official registry documentation&lt;/a&gt; and &lt;a class="reference external" href="http://zacharykeeton.com/docker-private-registry/"&gt;this blog post by
Zachary Keeton&lt;/a&gt;,
I managed to setup the registry as follows.&lt;/p&gt;
&lt;div class="section" id="host-setup"&gt;
&lt;h4&gt;Host setup&lt;/h4&gt;
&lt;p&gt;First, we need to setup a transport layer security (TLS)
certificate. It's possible to run the server without one if you don't
expect your network to be attacked, but it's good practice so let's
create one.&lt;/p&gt;
&lt;p&gt;To do this, I edit the /etc/ssl/openssl.cnf file and add the following
to the top of the [ v3_ca ] section.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
subjectAltName = IP:192.168.XXX.XXX
&lt;/pre&gt;
&lt;p&gt;where the IP address is the address of the workstation on the
network. Next, I actually create the certificate. I make a directory
called certs inside my workstation home directory and then use openssl
to make the cerficate. During the prompts, I press ENTER at every step
except the FQDN (fully qualified domain name). For the FQDN, I enter
the same IP address as above.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
mkdir certs
openssl req -newkey rsa:4096 -nodes -sha256 \
-keyout certs/domain.key -x509 -days 365 \
-config /etc/ssl/openssl.cnf -out certs/domain.crt
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;I had to add the ``-config /etc/ssl/openssl.cnf`` argument for the
subject alternative name to be added to the certificate.&lt;/strong&gt; This part
was tricky, because if this argument is not included, then the key
generation step will use some other .cnf file (I am not sure
which). This results in the following SAN error when attemptingt to
connect to the registry.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cannot validate certificate for 192.168.XXX.XXX because it doesn't contain any IP SANs
&lt;/pre&gt;
&lt;p&gt;After the domain.key and domain.crt files have been created, I run the
official registry server container. (See how handy Docker containers
are? There's no messy installation beyond grabbing the container.):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
docker run -d -p 5000:5000 \
  --restart=always \
  --name registry \
  -v $(pwd)/certs:/certs \
  -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \
  -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \
  registry:2
&lt;/pre&gt;
&lt;p&gt;If the registry:2 image is not already downloaded, then it will be
downloaded for automatically when running the container. Note that
the -p 5000:5000 argument indicates that the server is using port 5000
on both the host system and inside the container. Note also that the
certs directory is relative to the current directory because I use the
($pwd) command. You can change this to an absolute path if you wish on
your setup.&lt;/p&gt;
&lt;p&gt;Let's go ahead and push the application image to the server now that
it's running.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
docker push localhost:5000/rpi-micromanager:2.0-python
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="setup-the-pi"&gt;
&lt;h4&gt;Setup the Pi&lt;/h4&gt;
&lt;p&gt;Now, startup the Pi. I will assume that you have &lt;a class="reference external" href="https://www.raspberrypi.org/blog/docker-comes-to-raspberry-pi/"&gt;already installed
Docker&lt;/a&gt; on
it and know how to communicate with it via ssh and copy files to it
using scp.&lt;/p&gt;
&lt;p&gt;I copy the certificate from the host with scp:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo mkdir -p /etc/docker/certs.d/192.168.XXX.XXX:5000/
sudo scp kmdouglass@192.168.XXX.XXX:/home/kmdouglass/certs/domain.crt /etc/docker/certs.d/192.168.XXX.XXX:5000/ca.crt
&lt;/pre&gt;
&lt;p&gt;The IP address that I am using is the one to the machine where the
registry server is running. After this step, I make the operating
system trust the certificate:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo scp kmdouglass@192.168.XXX.XXX:/home/kmdouglass/certs/domain.crt /usr/local/share/ca-certificates/192.168.XXX.XXX.crt
sudo update-ca-certifications
&lt;/pre&gt;
&lt;p&gt;Finally, I restart the Docker daemon.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo service docker restart
&lt;/pre&gt;
&lt;p&gt;If everything is working, then I should be able to pull the image from
your network's registry server:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
docker pull 192.168.XXX.XXX:5000/rpi-micromanager:python2.0
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="step-5-run-micro-manager"&gt;
&lt;h3&gt;Step 5: Run Micro-Manager!&lt;/h3&gt;
&lt;p&gt;And now the moment of truth: running the application container. Since
it's setup to run Python automatically, I use a pretty simple &lt;tt class="docutils literal"&gt;docker
run&lt;/tt&gt; command.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
docker run -it --rm \
     --name micro-manager \
     192.168.XXX.XXX:5000/rpi-micromanager:2.0-python
&lt;/pre&gt;
&lt;p&gt;I verify that the Micro-Manager Python wrapper is working by trying to
import it and run &lt;a class="reference external" href="https://micro-manager.org/wiki/Using_the_Micro-Manager_python_library"&gt;a few basic commands&lt;/a&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;&amp;gt;&amp;gt; import MMCorePy
&amp;gt;&amp;gt;&amp;gt; mmc = MMCorePy.CMMCore()
&amp;gt;&amp;gt;&amp;gt; mmc.getVersionInfo()
&lt;/pre&gt;
&lt;p&gt;If these work without error, then congratulations! You're now ready to
start building your embedded microscopy system ;)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="step-6-running-the-whole-process"&gt;
&lt;h3&gt;Step 6: Running the whole process&lt;/h3&gt;
&lt;p&gt;The beauty of having scripted all these steps is that the full
workflow may be executed quite simply. From the host system's build
folder, run:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
kmdouglass@xxxxx:~/src/alphapi/docker/rpi-micromanager/build$ ./build
kmdouglass@xxxxx:~/src/alphapi/docker/rpi-micromanager/build$ ./run /path/to/source true
&lt;/pre&gt;
&lt;p&gt;From the 2.0-python folder:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
kmdouglass@xxxxx:~/src/alphapi/docker/rpi-micromanager/2.0-python ./build /path/to/source/artifacts
kmdouglass@xxxxx:~$ docker push localhost:5000/rpi-micromanager:2.0-python
&lt;/pre&gt;
&lt;p&gt;And from the Raspberry Pi:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
pi@yyyyy:~$ docker pull 192.168.XXX.XXX:5000/rpi-micromanager:2.0-python
pi@yyyyy:~$ docker run -it --rm \
                   --name micro-manager \
                   192.168.XXX.XXX:5000/rpi-micromanager:2.0-python
&lt;/pre&gt;
&lt;p&gt;Hopefully this is enough to get you started building Micro-Manager for
the Raspberry Pi with Docker. Though I focused on Micro-Manager, the
workflow should be generally applicable to any large scale project in
which you want to isolate the build environment from the host machine.&lt;/p&gt;
&lt;p&gt;If you have any questions, just leave them in the comments. Happy
programming!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>docker</category><category>micro-manager</category><category>raspberry pi</category><guid>http://kmdouglass.github.io/posts/how-i-built-a-cross-compilation-workflow-for-the-raspberry-pi.html</guid><pubDate>Sun, 29 Apr 2018 10:10:26 GMT</pubDate></item><item><title>Accessing the Raspberry Pi camera image sensor</title><link>http://kmdouglass.github.io/posts/accessing-the-raspberry-pi-camera-image-sensor.html</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt; You can easily ruin your Raspberry Pi camera module by
following the steps in this post. Proceed with caution.&lt;/p&gt;
&lt;p&gt;Over the past half year I have been making slow but steady progress on
&lt;a class="reference external" href="https://hackaday.io/project/19677-basic-lensless-imaging-for-low-cost-microscopy"&gt;my lensless imager project&lt;/a&gt;. The
purpose, aside from having a bit of fun, is to create an imaging
system for basic cell biology that doesn't use an expensive microscope
objective.&lt;/p&gt;
&lt;p&gt;A lensless imager works just as its name implies: an image sensor
records the scattered light from a microscopic, transparent object and
computationally reconstructs an image of that object, all without a
lens. The best resolutions are achieved when the object is relatively
close to the image sensor. Ideally, the separation between the object
and the sensor's pixels would be at most about one millimeter. &lt;a class="reference external" href="http://innovate.ee.ucla.edu/wp-content/uploads/2016/01/annurev-bioeng-092515-010849.pdf"&gt;This
limit is partly determined by the light source's spatial coherence&lt;/a&gt;,
but also by the fact that high resolution is achieved by recording the
scattered light at very large angles, which is possible only when the
sample is close to the sensor.&lt;/p&gt;
&lt;p&gt;Today I had a bit of free time so I decided to see whether I could
remove the housing that surrounds the Raspberry Pi camera's
sensor. The &lt;a class="reference external" href="https://www.raspberrypi.org/products/camera-module-v2/"&gt;Raspberry Pi Camera Module version 2&lt;/a&gt; sensor is a
Sony IMX219 color chip. Directly above the sensor is a filter, a lens,
and the housing for both of these that prevent me from placing
anything closer than about half a centimeter from the sensor plane. If
I would want to use this camera for the lensless imager, then the
housing would have to go.&lt;/p&gt;
&lt;p&gt;Now, even without the housing the Raspberry Pi camera is not
necessarily the best option for the project because the IMX219 is a
color sensor. This means that there is a Bayer filter over its pixels,
which would cut the resolution of the imager since I would be using a
very narrow band light source. Effectively, only a quarter of the
pixels would be receiving any light. Regardless, I had a spare second
camera and it interfaces well with the Raspberry Pi, so I figured it
would make for a good prototype.&lt;/p&gt;
&lt;p&gt;As you will see, I did slightly damage my sensor, though it seems to
still work. &lt;strong&gt;You can easily ruin your camera module or cut your
finger by following these steps, so proceed at your own risk.&lt;/strong&gt;&lt;/p&gt;
&lt;div class="section" id="step-0-the-raspberry-pi-camera-module-v2"&gt;
&lt;h2&gt;Step 0: The Raspberry Pi Camera Module V2&lt;/h2&gt;
&lt;p&gt;In the picture below you see my Raspberry Pi Camera Module. From
above, you can see the small circular aperture with the lens
immediately behind it. The sensor is inside the small gray rectangular
housing that is attached to the control board by a small ribbon cable
(to its right) and a bit of two-sided sticky foam tape (underneath the
sensor; not visible).&lt;/p&gt;
&lt;img alt="The Raspberry Pi Camera Module V2" class="align-center" src="http://kmdouglass.github.io/pi_camera_step0.jpg" style="width: 400px;"&gt;
&lt;/div&gt;
&lt;div class="section" id="step-1-remove-the-main-ribbon-cable"&gt;
&lt;h2&gt;Step 1: Remove the main ribbon cable&lt;/h2&gt;
&lt;p&gt;To make working on the board a bit easier, I removed the white ribbon
cable that attaches the module to the Pi. I did this by pulling on the
black tabs on the two ends of the connecter until the cable is easily
removed. I labeled the sides of the ribbon cable just in case.&lt;/p&gt;
&lt;img alt="Remove the main ribbon cable from the control board" class="align-center" src="http://kmdouglass.github.io/pi_camera_step1.jpg" style="width: 400px;"&gt;
&lt;/div&gt;
&lt;div class="section" id="step-2-detach-the-sensor-s-ribbon-cable"&gt;
&lt;h2&gt;Step 2: Detach the sensor's ribbon cable&lt;/h2&gt;
&lt;p&gt;Next, I used my finger and thumb nail to remove the small ribbon cable
that attaches the sensor to the control board. I essentially applied a
small torque to the bottom edge of the connector until it just
"popped" up, as seen in the second image below.&lt;/p&gt;
&lt;img alt="The small ribbon cable from the sensor is to the right." class="align-center" src="http://kmdouglass.github.io/pi_camera_step2.jpg" style="width: 400px;"&gt;
&lt;/div&gt;
&lt;div class="section" id="step-3-remove-the-sensor-from-the-control-board"&gt;
&lt;h2&gt;Step 3: Remove the sensor from the control board&lt;/h2&gt;
&lt;p&gt;In the third step, I used my thumbnail to gently pry the sensor from
the control board. The sensor is attached with some two-sided sticky
tape and may need a few minutes of work to come free.&lt;/p&gt;
&lt;img alt="Pull the sensor off the control board." class="align-center" src="http://kmdouglass.github.io/pi_camera_step3.jpg" style="width: 400px;"&gt;
&lt;/div&gt;
&lt;div class="section" id="step-4-remove-the-rectangular-housing"&gt;
&lt;h2&gt;Step 4: Remove the rectangular housing&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;In this step you risk cutting your finger, so please be careful.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The housing around the sensor is glued. To remove it, you will need to
gently work a knife (or, better yet, a thin screw driver) between the
housing and the sensor board, taking care not to let the blade go too
far into the housing and possibly ruining one of the resistors or wire
bonds.&lt;/p&gt;
&lt;img alt="Cut carefully on one side of the housing." class="align-center" src="http://kmdouglass.github.io/pi_camera_step4.jpg" style="width: 400px;"&gt;
&lt;p&gt;Once you get a knife between the two, try popping the housing off of
the sensor.&lt;/p&gt;
&lt;img alt="Once the edge is cut, pop the housing off." class="align-center" src="http://kmdouglass.github.io/pi_camera_step4b.jpg" style="width: 400px;"&gt;
&lt;p&gt;When I did this I cut on three sides of the housing, but in retrospect
I should have only cut on the side opposite the ribbon cable and pried
the other sides loose. This is because I damaged a small resistor when
the knife blade went too far into the housing. You can see this below
and, at the same time, get an idea of the layout of the sensor board
so you know where you can and can't cut.&lt;/p&gt;
&lt;img alt="The resistor near the top of the board was damaged when cutting the housing." class="align-center" src="http://kmdouglass.github.io/pi_camera_step4c.png" style="width: 400px;"&gt;
&lt;p&gt;If you have the normal version of the camera, then you can also find the IR blocking filter
inside the housing.&lt;/p&gt;
&lt;img alt="The IR blocking filter." class="align-center" src="http://kmdouglass.github.io/pi_camera_step4d.jpg" style="width: 400px;"&gt;
&lt;p&gt;Fortunately for me the camera still works, despite the damaged
resistor. I can now place samples directly on the sensor if I wanted
to, though the wire bonds from the sensor to its control board appear
quite fragile. For this reason, it may make more sense to build a
slide holder that holds a sample just above the surface without
touching it. For now, I can use this exposed sensor to prototype
different methods for mounting the sample.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>optics</category><category>photonics</category><category>raspberry pi</category><guid>http://kmdouglass.github.io/posts/accessing-the-raspberry-pi-camera-image-sensor.html</guid><pubDate>Sat, 26 Aug 2017 21:33:07 GMT</pubDate></item><item><title>Micro-Manager on the Raspberry Pi</title><link>http://kmdouglass.github.io/posts/micro-manager-on-the-raspberry-pi.html</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;a class="reference external" href="https://micro-manager.org/"&gt;Micro-Manager&lt;/a&gt; is an open source platform for controlling microscope
hardware, automating image acquisition, and tracking metadata about
how images are acquired. In biomedical imaging research, it serves as
an incredibly important tool because it is free and open source, which
means that scientists can benefit from the contributions of others to
the software without paying costly licensing fees.&lt;/p&gt;
&lt;p&gt;I recently managed to compile Micro-Manager version 2.0 on the
Raspberry Pi. I did this for a small hobby project I am working on to
build a cheap yet effective tool for &lt;a class="reference external" href="https://hackaday.io/project/19677-basic-lensless-imaging-for-low-cost-microscopy"&gt;at-home microscope projects and
hacking&lt;/a&gt;. Though I am not yet convinced that Micro-Manager will be
the best tool for this particular job given it's relatively heavy
footprint on the Pi's slower hardware, I thought that I would post my
notes so that others could benefit from my experience.&lt;/p&gt;
&lt;div class="section" id="software-versions"&gt;
&lt;h2&gt;Software versions&lt;/h2&gt;
&lt;p&gt;I am working with a Raspberry Pi 3 Model B:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
pi@raspberrypi:~ $ uname -a &amp;amp; gcc -dumpversion &amp;amp; make -v &amp;amp; ldd --version
Linux raspberrypi 4.4.38-v7+ #938 SMP Thu Dec 15 15:22:21 GMT 2016 armv7l GNU/Linux

pi@raspberrypi:~ $ gcc -dumpversion
4.9.2

pi@raspberrypi:~ $ make -v
GNU Make 4.0

pi@raspberrypi:~ $ ldd --version
ldd (Debian GLIBC 2.19-18+deb8u7) 2.19
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="setup-a-network-share-for-3rd-party-libraries"&gt;
&lt;h2&gt;Setup a network share for 3rd party libraries&lt;/h2&gt;
&lt;p&gt;We need to compile Micro-Manager because binares for the Pi's ARM
processor are not distributed by the Micro-Manager team (probably
because too few people have ever wanted them). To compile
Micro-Manager, we need to checkout a rather large set of 3rd party
libraries. When I last checked, these libraries occupied 6.7 GB of
space on my laptop, a size which can be prohibitive when using the
Micro-SD cards that provide storage for the Pi.&lt;/p&gt;
&lt;p&gt;To circumvent this problem, I checked out the &lt;strong&gt;3rdpartypublic&lt;/strong&gt; SVN
repository onto my laptop and created a network share from this
directory. Then, I mounted the share on my Pi in the directory just
above that containing the Micro-Manager source code.&lt;/p&gt;
&lt;p&gt;To get started, first have a look at my post on connecting a Pi to a
Linux home network for ideas if you haven't already connected the Pi
to your other machines at home:
&lt;a class="reference external" href="http://kmdouglass.github.io/posts/connecting-a-raspberry-pi-to-a-home-linux-network.html"&gt;http://kmdouglass.github.io/posts/connecting-a-raspberry-pi-to-a-home-linux-network.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Once the Pi and the laptop are on the same network, checkout the SVN
3rdpartypublic repository onto your laptop or home server. You may
need to do this a few times until completion because the downloads can
timeout after a few minutes:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
svn checkout https://valelab4.ucsf.edu/svn/3rdpartypublic/
&lt;/pre&gt;
&lt;p&gt;Next, we need to setup the network share. If your laptop or server is
running Windows, then you will probably need to setup &lt;a class="reference external" href="https://www.samba.org/samba/what_is_samba.html"&gt;Samba&lt;/a&gt; on the
Pi to share files between them. I however am running a Linux home
network, so I decided to use &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Network_File_System"&gt;NFS&lt;/a&gt; (Network File Sharing) to share
the directory between my laptop--which runs Debian Linux--and the
Pi. I installed NFS on my laptop with:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo apt-get install nfs-kernel-server nfs-common
&lt;/pre&gt;
&lt;p&gt;Once installed, I added the following line to the newly created
/etc/exports file:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/home/kmdouglass/src/micro-manager/3rdpartypublic 192.168.0.2/24(ro)
&lt;/pre&gt;
&lt;p&gt;The first part is the directory to share, i.e. where the
3rdpartypublic directory is stored on my laptop. The second part
contains the static IP address of the Pi on my home network. The /24
was REQUIRED for my client (the Pi) to mount the share. /24 simply
denotes a network mask of 255.255.255.0; if you have a different mask
on your network, then you can find a good discussion on this topic
here: &lt;a class="reference external" href="https://arstechnica.com/civis/viewtopic.php?t=751834"&gt;https://arstechnica.com/civis/viewtopic.php?t=751834&lt;/a&gt; Finally,
(...)  specifies shared options and &lt;strong&gt;ro&lt;/strong&gt; means read only.&lt;/p&gt;
&lt;p&gt;After editing the file, export the folder and restart the NFS server:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo exportfs -arv
sudo /etc/init.d/nfs-kernel-server restart
&lt;/pre&gt;
&lt;p&gt;On the client (the Pi), the NFS client software was already
installed. However, I had to restart the rpcbind service before I
could mount the share:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo /etc/init.d/rpcbind restart
&lt;/pre&gt;
&lt;p&gt;Finally, I added a line to the &lt;strong&gt;/etc/fstab&lt;/strong&gt; file on the Pi to make
mounting the 3rdpartypublic share easier:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
192.168.0.102:/home/kmdouglass/src/micro-manager/3rdpartypublic /home/pi/src/micro-manager/3rdpartypublic nfs user,noauto 0 0
&lt;/pre&gt;
&lt;p&gt;The first part indicates the IP of the laptop and the share to
mount. The second part, &lt;strong&gt;/home/pi/src/micro-manager/3rdpartypublic&lt;/strong&gt;
is the directory on the Pi where the share will be mounted. I placed
this one directory above where the MM source code is,
(&lt;strong&gt;/home/pi/src/micro-manager/micro-manager&lt;/strong&gt; on my machine). &lt;strong&gt;nfs&lt;/strong&gt;
indicates the type of share to mount, and &lt;strong&gt;user,noauto&lt;/strong&gt; permits any
user to mount the share (not just root), though this share will not be
automatically mounted when the Pi starts. The final two zeros are
explained in the fstab comments but aren't really important for us. To
mount the share, type the following on the Pi:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo mount /home/pi/src/micro-manager/3rdpartypublic
&lt;/pre&gt;
&lt;p&gt;In case you're interested in learning more about the intricacies of
Linux home networking, I found the following sources of information to
be incredibly helpful.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.howtoforge.com/install_nfs_server_and_client_on_debian_wheezy"&gt;https://www.howtoforge.com/install_nfs_server_and_client_on_debian_wheezy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.youtube.com/watch?v=luqq8DUqqCw"&gt;https://www.youtube.com/watch?v=luqq8DUqqCw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://nfs.sourceforge.net/nfs-howto/ar01s03.html#config_server_setup"&gt;http://nfs.sourceforge.net/nfs-howto/ar01s03.html#config_server_setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.tecmint.com/how-to-setup-nfs-server-in-linux/"&gt;http://www.tecmint.com/how-to-setup-nfs-server-in-linux/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="building-mm"&gt;
&lt;h2&gt;Building MM&lt;/h2&gt;
&lt;p&gt;Once I was able to mount the share containing 3rd party libraries, I
installed the following packages on the Pi and checked out the
Micro-Manager source code:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo apt-get install autoconf automake libtool pkg-config swig ant libboost-dev libboost-all-dev
cd ~/src/micro-manager
git clone https://github.com/micro-manager/micro-manager.git
cd micro-manager
git checkout mm2
&lt;/pre&gt;
&lt;p&gt;The last command switches to the mm2 branch where the Micro-Manager
2.0 source code is found. Note that it may not be necessary to install
all of the boost libraries with &lt;code&gt;sudo apt-get install
libboost-all-dev&lt;/code&gt;, but I did this anyway because I encountered
multiple errors due to missing boost library files the first few times
I tried compiling.&lt;/p&gt;
&lt;p&gt;The next step follows the normal Micro-Manager build routine using
make, with the exception of the configuration step. From inside the
Micro-Manager source code directory on the Pi, run the following
commands one at a time:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
./autogen.sh
PYTHON=/usr/bin/python3 ./configure --prefix=/opt/micro-manager --with-ij-jar=/usr/share/java/ij.jar --with-python=/usr/include/python3.4 --with-boost-libdir=/usr/lib/arm-linux-gnueabihf --with-boost=/usr/include/boost
make fetchdeps
make
sudo make install
&lt;/pre&gt;
&lt;p&gt;In the configuration step, I set the Python interpreter to Python 3
because I greatly prefer it over Python 2. This is done by setting the
&lt;strong&gt;PYTHON&lt;/strong&gt; environment variable before running
configure. &lt;strong&gt;--prefix=/opt/micro-manager/&lt;/strong&gt; indicates the preferred
installation directory of
Micro-Manager. &lt;strong&gt;--with-ij-jar=/usr/share/java/ij.jar&lt;/strong&gt; is the path to
the ImageJ Java library, though I am uncertain whether this was
necessary. (I installed ImageJ with a &lt;code&gt;sudo apt-get install
imagej&lt;/code&gt; a while ago.) &lt;strong&gt;--with-python=/usr/include/python3.4&lt;/strong&gt; should
point to the directory containing the &lt;strong&gt;Python.h&lt;/strong&gt; header file for the
version of Python you are compiling against. &lt;strong&gt;with-boost-libdir&lt;/strong&gt;
should point to the directory containing the boost libraries (.so
files). This was critical for getting MM2 to build. If you are unsure
where they are located, you can search for them with &lt;code&gt;sudo find
/ -name "libboost*"&lt;/code&gt;. Finally, the last option, &lt;strong&gt;with-boost&lt;/strong&gt;, may or
may not be necessary. I set it to the directory containing the boost
headers but never checked to see whether MM compiles without it.&lt;/p&gt;
&lt;p&gt;If all goes well, Micro-Manager will compile and install without
problems. Compilation time on my Pi took around one hour.&lt;/p&gt;
&lt;div class="section" id="set-the-maximum-amount-of-direct-memory"&gt;
&lt;h3&gt;Set the maximum amount of direct memory&lt;/h3&gt;
&lt;p&gt;In the next step, we need to make a minor edit to the Micro-Manager
Linux start script. Edit the script
(/opt/micro-manager/bin/micromanager) to reduce the maximum direct
memory to something reasonable:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/usr/lib/jvm/jdk-8-oracle-arm32-vfp-hflt/bin/java -Xmx1024M \
  -XX:MaxDirectMemorySize=1000G \
   -classpath "$CLASSPATH" \
   -Dmmcorej.library.loading.stderr.log=yes \
   -Dmmcorej.library.path="/opt/micro-manager/lib/micro-manager" \
   -Dorg.micromanager.plugin.path="/opt/micro-manager/share/micro-manager/mmplugins" \
&lt;/pre&gt;
&lt;p&gt;Change 1000G to 512M or 256M; otherwise the Pi will complain that the
MaxDirectMemorySize of 1000G is too large. You can start Micro-Manager
by running this modified script.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="what-s-next"&gt;
&lt;h2&gt;What's next?&lt;/h2&gt;
&lt;p&gt;Though Micro-Manager compiles and runs on the Pi, I have not yet
tested it thoroughly acquisitions. I am currently waiting on a camera
board to arrive in the mail, and when it does, I will attempt to
interface with it through Micro-Manager. Though I could write my own
Python library, Micro-Manager is appealing because it can save a lot
of time by providing a ready-made means to annotate, process, and
store imaging data.&lt;/p&gt;
&lt;p&gt;Running Micro-Manager on the Pi also raises the possibility of a fully
open, embedded biomedical imaging platform, though I am uncertain at
the moment whether the hardware on the Pi is up to the task. If you
manage to do anything cool with Micro-Manager and the Raspberry Pi,
please let me know in the comments!&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>micro-manager</category><category>microscopy</category><category>open source</category><category>raspberry pi</category><guid>http://kmdouglass.github.io/posts/micro-manager-on-the-raspberry-pi.html</guid><pubDate>Fri, 10 Feb 2017 18:31:57 GMT</pubDate></item><item><title>Connecting a Raspberry Pi to a home Linux network</title><link>http://kmdouglass.github.io/posts/connecting-a-raspberry-pi-to-a-home-linux-network.html</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;div&gt;&lt;p&gt;I recently purchased a Raspberry Pi 3 Model B and have been tinkering
with it for a few days. One of the first things I decided to do was to
set it up so that I could access it from my laptop over my home
network. This post contains a step-by-step explanation of the
process. If you have any questions, feel free to leave a comment or
send me an e-mail.&lt;/p&gt;
&lt;div class="section" id="collect-the-necessary-information"&gt;
&lt;h2&gt;Collect the necessary information&lt;/h2&gt;
&lt;p&gt;To start, we need to collect a little bit of information about the
home network. My internet is provided by a local company that supplied
me with a Thomson TWG-870 router. This router determines the IP
addresses of all the devices on my network. Since my laptop is running
Linux (Debian Jessie, to be exact), I can use the &lt;code&gt;netstat&lt;/code&gt;
command to get the IP address of the router.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
kmdouglass@kmd-laptop:~$ netstat -rn
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
0.0.0.0         192.168.0.1     0.0.0.0         UG        0 0          0 wlan0
&lt;/pre&gt;
&lt;p&gt;The key part of this output is the &lt;code&gt;Gateway&lt;/code&gt; column. A gateway
is the IP address of the device (i.e. the router) that provides
devices on a local network with access to the Internet.&lt;/p&gt;
&lt;p&gt;Knowing the IP address of the gateway, we can next trying entering it
directly into the address bar of a web browser. On my machine, this
opened a dialog asking for a username and password. (If you're not
sure what these are, try asking your ISP. And if you haven't changed
them from the default settings, then you really should do this.) After
entering them and clicking &lt;strong&gt;OK&lt;/strong&gt;, the browser window displayed the
general configuration pages for the router.&lt;/p&gt;
&lt;p&gt;The next few steps will depend on the specific router. The information
we are after is the list of IP addresses that the router reserves for
static IP's. A static IP address is an address that is assigned to a
device and doesn't change. Many routers have a so-called DHCP server
that dynamically assigns IP addresses to devices such as smart phones
as they log onto the network. We probably want to always find the Pi
at the same address, however, so a static IP makes more sense than one
that the router dynamically assigns.&lt;/p&gt;
&lt;p&gt;To find the list of static IP's on my specific router, I clicked on
the link entitled &lt;strong&gt;Network&lt;/strong&gt; in my router's configuration page. The
relevant information for me looks like that in the image below:&lt;/p&gt;
&lt;img alt="DHCP address pool" class="align-center" src="http://kmdouglass.github.io/dhcp_addresses.png"&gt;
&lt;p&gt;This information is telling us that the router is reserving addresses
192.168.0.10 to 192.168.0.254 for the DHCP server. We can therefore
most probably use 192.168.0.2 through 9 for static IP's. (Remember
that 192.168.0.1 is already taken; it's the address of the router.) I
tested 192.168.0.2 by pinging it and received no response, so we will
use this address for my Raspberry Pi. (Use Ctrl-C to stop pinging the
device.):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
kmdouglass@kmd-laptop:~$ ping 192.168.0.2
PING 192.168.0.2 (192.168.0.2) 56(84) bytes of data.
From 192.168.0.15 icmp_seq=1 Destination Host Unreachable
From 192.168.0.15 icmp_seq=2 Destination Host Unreachable
From 192.168.0.15 icmp_seq=3 Destination Host Unreachable
^C
--- 192.168.0.2 ping statistics ---
4 packets transmitted, 0 received, +3 errors, 100% packet loss, time 3014ms
pipe 3
&lt;/pre&gt;
&lt;p&gt;For the next step, we need to collect the broadcast and subnet mask of
the network. We can do this from the laptop that is already connected
to the network by running the &lt;code&gt;sudo ifconfig&lt;/code&gt; command. This
command will report information that looks similar to the following
example (note that this is not from my machine but is merely for
illustration)::&lt;/p&gt;
&lt;pre class="literal-block"&gt;
eth0 Link encap:Ethernet HWaddr 00:10:5A:1A:DC:65
inet addr:198.209.253.169 Bcast:208.141.109.255 Mask:255.255.255.0
UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1
RX packets:18940 errors:1 dropped:0 overruns:0 frame:2
TX packets:11554 errors:0 dropped:0 overruns:0 carrier:0
collisions:2 txqueuelen:100
RX bytes:4087250 (3.8 Mb) TX bytes:2499423 (2.3 Mb)
Interrupt:11 Base address:0xd000
&lt;/pre&gt;
&lt;p&gt;The very first line tells us that this block of output belongs to the
&lt;strong&gt;eth0&lt;/strong&gt; interface. If you connect to the internet on your laptop
through WiFi, then you may need to find the information for the
&lt;strong&gt;wlan0&lt;/strong&gt; interface instead. wlan0 is usually used to refer to
wireless interfaces in Ubuntu and Debian Linux.&lt;/p&gt;
&lt;p&gt;The first line of output from ifconfig also provides the type of
hardware and the ID of the ethernet card. The information we need,
however, is on the second line. The device's IP address on the network
is &lt;strong&gt;inet addr:198.209.253.169&lt;/strong&gt;, but we don't really need this
information. Rather, we need the two numbers that come next. The
broadcast IP is reported in &lt;strong&gt;Bcast:208.141.109.255&lt;/strong&gt; and the subnet
mask in &lt;strong&gt;Mask:255.255.255.0&lt;/strong&gt;. The &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Broadcast_address"&gt;broadcast IP&lt;/a&gt; is used to send
messages to all devices on the network, whereas the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Subnetwork"&gt;subnet mask&lt;/a&gt; is
used to separate the parts of an address that identify the network
from the parts that identify the devices and possible "sub-networks."&lt;/p&gt;
&lt;p&gt;To summarize this section, we need:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The static IP address that we'll assign to the Pi&lt;/li&gt;
&lt;li&gt;The IP address of the router, i.e. the gateway address&lt;/li&gt;
&lt;li&gt;The broadcast IP&lt;/li&gt;
&lt;li&gt;The subnet mask&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="configure-the-pi"&gt;
&lt;h2&gt;Configure the Pi&lt;/h2&gt;
&lt;p&gt;Now that we have decided on an IP address for the Pi, let's boot it up
and configure it to always use this IP address. (I am currently using
the &lt;strong&gt;NOOBS&lt;/strong&gt; operating system that came with my Pi starter kit, but
this should work with other flavors of Debian Linux as well.)&lt;/p&gt;
&lt;p&gt;Once logged on to the Pi, open a terminal and make a backup copy of
the file &lt;strong&gt;/etc/network/interfaces&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo cp /etc/network/interfaces /etc/network/interfaces.bak
&lt;/pre&gt;
&lt;p&gt;Making a backup is good practice; in case we ruin the configuration
file, we can simply rewrite it using our backup. Next, open the
original &lt;strong&gt;interfaces&lt;/strong&gt; file for editing. In this example, I'll use
the &lt;strong&gt;nano&lt;/strong&gt; editor:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo nano /etc/network/interfaces
&lt;/pre&gt;
&lt;p&gt;In this file, add the following lines (replacing the addresses with
those appropriate for your network):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
auto eth0
iface eth0 inet static
    address 192.168.0.2
    netmask 255.255.255.0
    gateway 192.168.0.1
    broadcast 192.168.0.255
&lt;/pre&gt;
&lt;p&gt;What do these lines do, you ask? Let's step through them one-by-one.&lt;/p&gt;
&lt;div class="section" id="start-the-network-interface-at-boot"&gt;
&lt;h3&gt;Start the network interface at boot&lt;/h3&gt;
&lt;p&gt;First off, we need to identify the network interface. &lt;strong&gt;eth0&lt;/strong&gt; is the
identifier that is referring to the dedicated ethernet port on the
Pi. The line &lt;strong&gt;auto eth0&lt;/strong&gt; means that this interface will be started
at boot.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="configure-the-interface-to-use-a-static-ip"&gt;
&lt;h3&gt;Configure the interface to use a static IP&lt;/h3&gt;
&lt;p&gt;Next, we see the line &lt;strong&gt;iface eth0 inet static&lt;/strong&gt;. First, &lt;strong&gt;iface
eth0&lt;/strong&gt; means that we are configuring the ethernet port interface that
was described in the last section. Following that, &lt;strong&gt;inet&lt;/strong&gt; specifies
that the interface uses TCP/IP networking. Finally, &lt;strong&gt;static&lt;/strong&gt; is
telling the NOOBS operating system that the device is going to request
a static IP address from the router. (I obtained this explanation from
&lt;a class="reference external" href="http://askubuntu.com/questions/411616/what-does-keywords-in-my-etc-network-interfaces-means"&gt;this forum post&lt;/a&gt;.)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="set-the-various-addresses"&gt;
&lt;h3&gt;Set the various addresses&lt;/h3&gt;
&lt;p&gt;The next lines are indented because they are properties of the &lt;strong&gt;inet
static&lt;/strong&gt; family. If you've read everything until now, you should be
able to figure out what addresses to enter next for each option. The
desired static IP address for the Pi should follow the &lt;strong&gt;address&lt;/strong&gt;
field; the subnet mask, gateway, and broadcast IP's described above
should follow &lt;strong&gt;netmask&lt;/strong&gt;, &lt;strong&gt;gateway&lt;/strong&gt;, and &lt;strong&gt;broadcast&lt;/strong&gt;
respectively.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;network&lt;/strong&gt; property (which is not shown above) contains the
network address and &lt;a class="reference external" href="http://man.cx/interfaces%285%29"&gt;is required for 2.0.x kernels&lt;/a&gt;. These kernels
are pretty old by now, so it is unlikely that you will need to specify
this property.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="restart-the-network-interface"&gt;
&lt;h3&gt;Restart the network interface&lt;/h3&gt;
&lt;p&gt;Restarting the interface we just configured on our Pi is as simple
as entering these terminal commands:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo ifdown eth0
sudo ifup eth0
&lt;/pre&gt;
&lt;p&gt;(Remember to replace eth0 with the appropriate interface if yours is
different.) If everything goes well, we should be able to use our web
browser to navigate on the Internet. We should also be able to ping
the Pi from the laptop and vice versa.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="connecting-to-the-pi"&gt;
&lt;h2&gt;Connecting to the Pi&lt;/h2&gt;
&lt;p&gt;Once the Pi is on the network, we need a way to connect to it from the
laptop and other devices so that we can actually use it for
something. One way is to use &lt;a class="reference external" href="https://support.suso.com/supki/SSH_Tutorial_for_Linux"&gt;ssh&lt;/a&gt;, or Secure SHell. ssh is program
that let's us securely log on to other devices through a shell
(i.e. terminal). This is useful for when we need to work only on the
command line.&lt;/p&gt;
&lt;p&gt;If, on the other hand, we want a "Remote Desktop"-like GUI
environment, we can use &lt;a class="reference external" href="https://www.raspberrypi.org/documentation/remote-access/vnc/"&gt;VNC&lt;/a&gt;. The documentation for VNC is quite
good but detailed; I'll let you read up on it on your own if you're
interested in using it.&lt;/p&gt;
&lt;p&gt;I'll now briefly explain how we can set up ssh on the Pi.&lt;/p&gt;
&lt;div class="section" id="edit-vnc-installation"&gt;
&lt;h3&gt;EDIT: VNC installation&lt;/h3&gt;
&lt;p&gt;As it turns out, you may run into some problems if you do try to setup
VNC by following the documentation in the link above. Namely, the
documentation is missing a key step, at least for me. I had to first
install the VNC server software on the Pi via:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo apt-get update
sudo apt-get install realvnc-vnc-server
&lt;/pre&gt;
&lt;p&gt;Even though the rest of this post is about ssh, you may still find
this information useful.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="enable-ssh-on-the-pi"&gt;
&lt;h3&gt;Enable ssh on the Pi&lt;/h3&gt;
&lt;p&gt;We need to enable ssh access to the Pi before we can use it. On the
Pi, open a terminal and run the configuration utility::&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo raspi-config
&lt;/pre&gt;
&lt;p&gt;We should see the following window appear.&lt;/p&gt;
&lt;img alt="The raspi-config menu with Interface Options highlighted." class="align-center" src="http://kmdouglass.github.io/pi-config-interface-options.png"&gt;
&lt;p&gt;Use the keyboard to highlight &lt;strong&gt;Interface Options&lt;/strong&gt; and tap the Enter
key. In the following menu, we now should see an option to enable ssh
as in the following image. Use the keyboard to highlight &lt;strong&gt;P2 SSH&lt;/strong&gt;
(or the relevant menu item if the name is different on your Pi) and
hit the Enter key to enable it. Once ssh is enabled, we can hit Esc or
select the &amp;lt;Back&amp;gt; option to until we exit the configuration utility.&lt;/p&gt;
&lt;img alt="The raspi-config Interface Options menu with P2 SSH highlighted." class="align-center" src="http://kmdouglass.github.io/pi-config-ssh.png"&gt;
&lt;p&gt;If you'e following along, you may need to restart your Pi for these
changes to take effect.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="log-onto-the-pi-from-the-laptop"&gt;
&lt;h3&gt;Log onto the Pi from the laptop&lt;/h3&gt;
&lt;p&gt;Now for the moment of truth. After restarting the Pi, &lt;strong&gt;we need to
first ensure that we are not logged in to it&lt;/strong&gt;. If we are, simply
click the &lt;strong&gt;Menu&lt;/strong&gt; button, followed by &lt;strong&gt;Shutdown... -&amp;gt; Logout&lt;/strong&gt; and
log out of the session.&lt;/p&gt;
&lt;p&gt;Next, open a terminal on the laptop and enter the following command,
changing the IP address to whatever was decided upon for the Pi::&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ssh pi@192.168.0.2
&lt;/pre&gt;
&lt;p&gt;This command runs the ssh program and asks to sign into the Pi as the
user called &lt;strong&gt;pi&lt;/strong&gt;. After running the command, we may be prompted for
a password to log on if one was set on the Pi. (You did set one,
didn't you?) Once successfully entering the password, we should notice
that the terminal prompt has changed to something like
&lt;code&gt;pi@raspberrypi:~ $&lt;/code&gt;. This indicates that we are logged on to
the Pi. If we enter the &lt;code&gt;ls&lt;/code&gt; command, we should see the contents
of the Pi's home directory. When we're ready to disconnect from the
Pi, we can simply use the &lt;code&gt;exit&lt;/code&gt; command at any time in the
terminal. The prompt should change to reflect that we are back on our
laptop machine when we have successfully exited.&lt;/p&gt;
&lt;p&gt;If this is all working as described above, then congratulations on
connecting your Pi to your home Linux network! I wish you many happy
hours of hacking :)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="further-reading"&gt;
&lt;h2&gt;Further Reading&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The Debian network setup manual is very detailed and describes
many, many more aspects of setting up a network than I touched upon
here. &lt;a class="reference external" href="https://www.debian.org/doc/manuals/debian-reference/ch05.en.html"&gt;https://www.debian.org/doc/manuals/debian-reference/ch05.en.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The Raspberry Pi documentation about VNC (Virtual Network
Computing) is a great resource for setting up a graphical interface
to remotely connect to your
Pi. &lt;a class="reference external" href="https://www.raspberrypi.org/documentation/remote-access/vnc/"&gt;https://www.raspberrypi.org/documentation/remote-access/vnc/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>linux</category><category>raspberry pi</category><guid>http://kmdouglass.github.io/posts/connecting-a-raspberry-pi-to-a-home-linux-network.html</guid><pubDate>Sun, 05 Feb 2017 09:28:17 GMT</pubDate></item></channel></rss>