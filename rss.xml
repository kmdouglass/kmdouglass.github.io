<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kyle M. Douglass</title><link>http://kmdouglass.github.io/</link><description>Biophysics, optics, and programming.</description><atom:link rel="self" href="http://kmdouglass.github.io/rss.xml" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sat, 28 Nov 2015 08:10:54 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Beware the paraxial approximation in microscopy</title><link>http://kmdouglass.github.io/posts/beware-the-paraxial-approximation-in-microscopy.html</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;p&gt;
I have had a difficult time resolving what originally seemed to be an
inconsistency between a 2004 research article about estimating
microscope pupil functions and the body of knowledge concerning the
theory of aberrations in optical systems.
&lt;/p&gt;

&lt;p&gt;
In the article by Hanser, et al.&lt;sup&gt;&lt;a id="fnr.1" name="fnr.1" class="footref" href="http://kmdouglass.github.io/posts/beware-the-paraxial-approximation-in-microscopy.html#fn.1"&gt;1&lt;/a&gt;&lt;/sup&gt;, the authors utilize an imaging model
for calculating the amplitude point-spread function of an optical
system that incorporates defocus as an exponential term inside the
Fourier transform integral:
&lt;/p&gt;

\begin{equation*}
\text{PSF}_{\text{A}} \left( x, y, z \right) = \iint_{pupil} P \left( k_x, k_y \right) e^{i k_z z} e^{i \left( k_{x}x + k_{y}y \right)} dk_x dk_y
\end{equation*}

&lt;p&gt;
where \(k_z = \sqrt{\left( 2 \pi n / \lambda \right)^2 - \left( k_x^2 +
k_y^2 \right)}\). (I changed the notation of some variables used in the
text because the authors confusingly use \(k\) to represent spatial
frequency in units of &lt;i&gt;cycles per distance&lt;/i&gt; instead of the much more
common &lt;i&gt;radians per distance&lt;/i&gt;.) In the image plane at \(z = 0\), there
is no defocus and we get the amplitude point spread function (PSF) as
the Fourier transform of the pupil function \(P \left( k_x, k_y
\right)\) just like we would expect (see Goodman&lt;sup&gt;&lt;a id="fnr.2" name="fnr.2" class="footref" href="http://kmdouglass.github.io/posts/beware-the-paraxial-approximation-in-microscopy.html#fn.2"&gt;2&lt;/a&gt;&lt;/sup&gt;, Chapter 6,
pp. 129-131).
&lt;/p&gt;

&lt;p&gt;
The problem arises when I try to verify this model when \(z\) is not
equal to zero by computing the defocused PSF using the wavefront error
for defocus. From the scalar diffraction theory of aberrations, the
defocused PSF is the Fourier transform of the pupil function
multiplied by a phase factor whose phase angle is proportional to the
wavefront error \(W \left( k_x, k_y \right)\)
&lt;/p&gt;

\begin{equation*}
\text{PSF}_{\text{A}} \left( x, y, z \right) = \iint_{pupil} P \left( k_x, k_y \right) e^{i k W \left( k_x, k_y \right)} e^{i \left( k_{x}x + k_{y}y \right)} dk_x dk_y
\end{equation*}

&lt;p&gt;
Any textbook discussing Seidel aberrations will tell you that the
defocused wavefront error \(W\) is quadratic in the pupil plane
coordinates, i.e. \(W \sim k_x^2 + k_y^2\). Goodman even states this
with little justification later in Chapter 6 on p. 149 when discussing
defocus &lt;sup&gt;&lt;a id="fnr.2.100" name="fnr.2.100" class="footref" href="http://kmdouglass.github.io/posts/beware-the-paraxial-approximation-in-microscopy.html#fn.2"&gt;2&lt;/a&gt;&lt;/sup&gt;. So how can I reconcile the first equation in which the
defocus goes as the square root of a constant minus the squared pupil
coordinates with the second equation that is quadratic in pupil
coordinates?
&lt;/p&gt;

&lt;p&gt;
The answer, as you might have guessed from the title of this post, is
that &lt;i&gt;the Seidel polynomial term for defocus is a result of applying
the paraxial approximation when computing the wavefront error&lt;/i&gt;. You
can see this by calculating the phase of a spherical wave in the pupil
plane that is centered on the axis in the image plane; Goodman states
it is quadratic without justification, but this is only true near the
axis. Mahajan offers a geometrical interpretation of \(W\) on p. 148,
where he notes that the path length difference for defocus "is
approximately equal to the difference of &lt;a href="http://liutaiomottola.com/formulae/sag.htm"&gt;sags&lt;/a&gt; of the reference sphere
and the wavefront.&lt;sup&gt;&lt;a id="fnr.3" name="fnr.3" class="footref" href="http://kmdouglass.github.io/posts/beware-the-paraxial-approximation-in-microscopy.html#fn.3"&gt;3&lt;/a&gt;&lt;/sup&gt;" He then goes on to derive the same expression
for \(W\) that Goodman gets; he states the approximation that he uses,
whereas Goodman implicitly assumes a quadratic phase front in the
pupil. Hanser et al., on the other hand, are essentially propagating
the plane wave angular spectrum from the image plane to nearby planes
to model defocus. I think that this should be rigorously correct since
no approximation is applied. For me, it is unfortunate that this was
not made clear in their paper because I spent quite a bit of time
trying to reconcile the two results.
&lt;/p&gt;

&lt;p&gt;
The lesson of this story is to be sure you know about the
approximations that go into a "standard" result found in textbooks. I
falsely assumed that the Seidel aberrations were exact and that
Hanser, et al. were suspect when in fact it was the other way
around. Because the paraxial approximation is so widespread in optics
theory, it can often lie hidden behind an equation and its effects can
easily be taken for granted. This is a problem for the large NA
systems used in microscopy where the results of the paraxial
approximation are not often valid.
&lt;/p&gt;
&lt;div id="footnotes"&gt;
&lt;h2 class="footnotes"&gt;Footnotes: &lt;/h2&gt;
&lt;div id="text-footnotes"&gt;

&lt;div class="footdef"&gt;&lt;sup&gt;&lt;a id="fn.1" name="fn.1" class="footnum" href="http://kmdouglass.github.io/posts/beware-the-paraxial-approximation-in-microscopy.html#fnr.1"&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;p class="footpara"&gt;
&lt;a href="http://onlinelibrary.wiley.com/doi/10.1111/j.0022-2720.2004.01393.x/abstract;jsessionid=946CF30FA7FA65F1DB4C638D0C4DF00F.f02t04"&gt;http://onlinelibrary.wiley.com/doi/10.1111/j.0022-2720.2004.01393.x/abstract;jsessionid=946CF30FA7FA65F1DB4C638D0C4DF00F.f02t04&lt;/a&gt;
&lt;/p&gt;&lt;/div&gt;

&lt;div class="footdef"&gt;&lt;sup&gt;&lt;a id="fn.2" name="fn.2" class="footnum" href="http://kmdouglass.github.io/posts/beware-the-paraxial-approximation-in-microscopy.html#fnr.2"&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;p class="footpara"&gt;
&lt;a href="https://books.google.ch/books/about/Introduction_to_Fourier_optics.html?id=ow5xs_Rtt9AC&amp;amp;redir_esc=y"&gt;https://books.google.ch/books/about/Introduction_to_Fourier_optics.html?id=ow5xs_Rtt9AC&amp;amp;redir_esc=y&lt;/a&gt;
&lt;/p&gt;&lt;/div&gt;

&lt;div class="footdef"&gt;&lt;sup&gt;&lt;a id="fn.3" name="fn.3" class="footnum" href="http://kmdouglass.github.io/posts/beware-the-paraxial-approximation-in-microscopy.html#fnr.3"&gt;3&lt;/a&gt;&lt;/sup&gt; &lt;p class="footpara"&gt;
&lt;a href="https://books.google.ch/books/about/Optical_Imaging_and_Aberrations_Ray_geom.html?id=I_1AAQAAIAAJ&amp;amp;redir_esc=y"&gt;https://books.google.ch/books/about/Optical_Imaging_and_Aberrations_Ray_geom.html?id=I_1AAQAAIAAJ&amp;amp;redir_esc=y&lt;/a&gt;
&lt;/p&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;/div&gt;</description><category>microscopy</category><category>optics</category><guid>http://kmdouglass.github.io/posts/beware-the-paraxial-approximation-in-microscopy.html</guid><pubDate>Wed, 09 Sep 2015 17:40:00 GMT</pubDate></item><item><title>What's the difference between a back focal plane and pupil plane?</title><link>http://kmdouglass.github.io/posts/whats-the-difference-between-a-back-focal-plane-and-pupil-plane.html</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;p&gt;
Yesterday in the lab I asked one of my colleagues whether she knew
what the pupil plane of a microscope objective was. Her answer was
no. I then unknowingly proceeded to give her a description which I now
realize was false. I said that the pupil plane is the plane near the
backside of the objective where the light intensity is proportional to
the Fourier transform of the image. Later that evening, I realized
that this explanation was, in fact, wrong. I had described to her what
is the &lt;i&gt;back focal plane&lt;/i&gt; for an infinity-corrected objective.
&lt;/p&gt;

&lt;p&gt;
Don't worry, I will correct myself when I see her later
today. However, this experience does raise one important question that
I have never seriously considered in optics: what is the meaningful
difference between the pupil plane of an optical system and its back
focal plane?
&lt;/p&gt;

&lt;p&gt;
First, I should point out that there is no difference between a &lt;i&gt;back&lt;/i&gt;
focal plane and one of the two focal planes of an objective; these are
merely semantics that reflect the fact that we think of the sample as
being in front of the objective. The back focal plane is therefore the
focal plane of the objective located on the side opposite the
sample. Now, everyone who has taken a Fourier optics class has
probably learned the following mantra:
&lt;/p&gt;

&lt;div align="center"&gt;

&lt;p&gt;
&lt;b&gt;The focal plane of a lens contains the Fourier transform of the
object.&lt;/b&gt;
&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;
Of course, this statement is usually what we remember, but in fact it
should look more like this:
&lt;/p&gt;

&lt;div align="center"&gt;


&lt;p&gt;
&lt;b&gt;The focal plane of a lens contains the Fourier transform of the
object, except for every other detail we ignore in the math.&lt;/b&gt;
&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;
While it's true that the light intensity here reflects the sample's
two-dimensional Fourier transform, the general case often contains
additional phase factors and expressions to account for the pupil size
and apodization (see &lt;a href="https://books.google.ch/books?id=ow5xs_Rtt9AC&amp;amp;printsec=frontcover&amp;amp;dq=goodman+fourier+optics&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ved=0CB0Q6AEwAGoVChMI-5vjt5jGxwIVCMUUCh37ogzP#v=onepage&amp;amp;q=goodman%20fourier%20optics&amp;amp;f=false"&gt;Goodman&lt;/a&gt;, section 5.2). Regardless, it is in the
back focal plane where the light intensity contains information on the
angular spectrum that makes up the object.
&lt;/p&gt;

&lt;p&gt;
In contrast, the pupil plane contains either the image of the
objective's aperture stop or the physical stop itself, depending on
what sets the limit on the numerical aperture of the objective in the
infinity space (again, see &lt;a href="https://books.google.ch/books?id=ow5xs_Rtt9AC&amp;amp;printsec=frontcover&amp;amp;dq=goodman+fourier+optics&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ved=0CB0Q6AEwAGoVChMI-5vjt5jGxwIVCMUUCh37ogzP#v=onepage&amp;amp;q=goodman%20fourier%20optics&amp;amp;f=false"&gt;Goodman&lt;/a&gt;, appendix B). Moreover, the pupil
plane is also used as the reference plane for quantifying the
objective's aberrations. This is because, for a diffraction-limited
system, the wavefront in the (exit) pupil plane will be a spherical
wave converging towards the image of a point source and truncated by
the aperture stop (&lt;a href="https://books.google.ch/books?id=ow5xs_Rtt9AC&amp;amp;printsec=frontcover&amp;amp;dq=goodman+fourier+optics&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ved=0CB0Q6AEwAGoVChMI-5vjt5jGxwIVCMUUCh37ogzP#v=onepage&amp;amp;q=goodman%20fourier%20optics&amp;amp;f=false"&gt;Goodman&lt;/a&gt; again discusses this in section
6.1). Deviations from the spherical reference wave serve as the means
to quantify the aberrations in a system.
&lt;/p&gt;

&lt;p&gt;
From an experimental point of view, the back focal plane is
interesting because it is used in Fourier microscopy, for which many
setups have been devised to image it (see Figure 1 in &lt;a href="http://arxiv.org/abs/1507.04037"&gt;this excellent
arXiv submission&lt;/a&gt;.) What I really am wondering now is how one would go
about imaging the pupil plane as a means of exploring an objective's
aberrations, and whether this is at all feasible.
&lt;/p&gt;</description><category>optics</category><guid>http://kmdouglass.github.io/posts/whats-the-difference-between-a-back-focal-plane-and-pupil-plane.html</guid><pubDate>Wed, 26 Aug 2015 06:49:13 GMT</pubDate></item><item><title>Paraxial Optics (2): What problem does it solve?</title><link>http://kmdouglass.github.io/posts/paraxial-optics-2-what-problem-does-it-solve.html</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;div id="outline-container-sec-1" class="outline-2"&gt;
&lt;h2 id="sec-1"&gt;Summary&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-1"&gt;
&lt;ol class="org-ol"&gt;
&lt;li&gt;Paraxial optics is a tool to aid in building optical systems.
&lt;/li&gt;
&lt;li&gt;Paraxial optics solves the imaging problem.
&lt;/li&gt;
&lt;li&gt;The imaging problem concerns finding the location, size, and
orientation of an image given an object and an optical system.
&lt;/li&gt;
&lt;li&gt;An optical system is a collection of objects like lenses, mirrors,
prisms, cameras, etc. that collects the light emitted or scattered
by an object and delivers it to another location where it can be
detected and processed for information.
&lt;/li&gt;
&lt;li&gt;The rules of paraxial optics allow for a perfect imaging system,
i.e. a system that creates a one-to-one correspondance between
points in an object plane and an image plane.
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-2" class="outline-2"&gt;
&lt;h2 id="sec-2"&gt;Paraxial optics solves the imaging problem&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-2"&gt;
&lt;p&gt;
&lt;i&gt;In this post I will use paraxial optics to mean paraxial geometrical
optics. This is important since the paraxial approximation can also&lt;/i&gt;
&lt;i&gt;apply to the wave theory of light.&lt;/i&gt;
&lt;/p&gt;

&lt;p&gt;
When learning a new theory, I often find it most useful to first
identify the problem that the theory was developed to solve. This
approach is particularly pertinent for learning paraxial optics, since
the theory is largely used as a tool to aid in the construction of
optical systems. Unfortunately, the fact that paraxial optics can help
solve problems often becomes lost on people because they never
actually build anything for the purpose of imaging. And even if a
someone never builds a camera or microscope, I think it is difficult
for them to see what paraxial optics concepts–such as principle
planes and aperture stops–can do for helping them troubleshoot their
hardware when it is not working as expected.
&lt;/p&gt;

&lt;p&gt;
So, with this in mind, I will use this part in a series of blog posts
to answer the following question: what is the problem that paraxial
optics solves?
&lt;/p&gt;

&lt;p&gt;
Paraxial optics solves the imaging problem &lt;sup&gt;&lt;a id="fnr.1" name="fnr.1" class="footref" href="http://kmdouglass.github.io/posts/paraxial-optics-2-what-problem-does-it-solve.html#fn.1"&gt;1&lt;/a&gt;&lt;/sup&gt;. The imaging problem as
I see it is simply this: &lt;b&gt;given an optical system, how can one arrange
its components to form the image of an object at a desired&lt;/b&gt; &lt;b&gt;position
and with a predictable size and orientation?&lt;/b&gt; This question has been
asked by scientists, engineers, philosophers, and others since
antiquity because we place enormous value in pictures.
&lt;/p&gt;

&lt;p&gt;
To better understand this problem, I am going to step through the
parts of this statement and explain what I mean by each. First, I
mention that the imaging problem involves the use of an &lt;b&gt;optical
system&lt;/b&gt;. I have to admit that I use this term partly because it is
part of the jargon of the optical sciences, but I also think that the
word "system" nicely captures the essence of what I would like to
say. An optical system is a collection of components such as lenses,
mirrors, and prisms taken together with their mechanical supports and
arranged in a meaningful way to capture and channel light as it
travels from one place to another. Below is one example of an optical
system that most people know pretty well.
&lt;/p&gt;

&lt;div align="center"&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="http://kmdouglass.github.io/eye.jpg" alt="eye.jpg"&gt;
&lt;/p&gt;
&lt;/div&gt;

  A human eye is an optical system! From &lt;a href="http://en.wikipedia.org/wiki/Eye#/media/File:Eye_iris.jpg"&gt;
  Peter Nóvak, Wikipedia&lt;/a&gt;.
&lt;/div&gt;

&lt;p&gt;
I have already mentioned that the components of an optical system can
include things we commonly associate with optics, such as lenses and
mirrors, but really no one such component is necessary to build an
optical system so long as it captures and does something with
light. For example, &lt;a href="http://en.wikipedia.org/wiki/Pinhole_camera"&gt;the pinhole camera&lt;/a&gt; uses nothing but a very small
hole to form images; no lens is required! Still, we usually find some
components like lenses much more frequently in optical systems than
others, and the choice of which components to use really just depends
on the specific type of imaging problem you are trying to solve.
&lt;/p&gt;

&lt;p&gt;
Next in the statement of the imaging problem I say that we will be
forming an image by arranging the components of our optical system in
a clever way. Though the intuitive notion of an image is quite clear,
I think it is actually extremely difficult to formally define it. For
the purpose of this tutorial, I think it is best at this point to rely
on the intuitive idea of an image until I have developed enough
concepts to define it in terms of optical theory &lt;sup&gt;&lt;a id="fnr.2" name="fnr.2" class="footref" href="http://kmdouglass.github.io/posts/paraxial-optics-2-what-problem-does-it-solve.html#fn.2"&gt;2&lt;/a&gt;&lt;/sup&gt;.
&lt;/p&gt;

&lt;p&gt;
Finally, the imaging problem involves determining the location, size,
and orientation of an image formed by the system. This means that
rearrangement of our system's components is going to change these
features of the image. Things such as the size of a CCD chip or the
weight of a lens are going to place constraints on the values these
properties can take.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-3" class="outline-2"&gt;
&lt;h2 id="sec-3"&gt;Perfect imaging systems&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-3"&gt;
&lt;p&gt;
At this point I should stress that paraxial optics is not the only
theoretical tool for solving the imaging problem. We clearly can use
non-paraxial geometrical optics or wave optics to determine the
properties of an image formed by an optical system. However, what is
interesting is that paraxial optics is one of very few theoretical
frameworks in which a perfect image can be realized &lt;sup&gt;&lt;a id="fnr.3" name="fnr.3" class="footref" href="http://kmdouglass.github.io/posts/paraxial-optics-2-what-problem-does-it-solve.html#fn.3"&gt;3&lt;/a&gt;&lt;/sup&gt;.
&lt;/p&gt;

&lt;div align="center"&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="http://kmdouglass.github.io/im_perfectOpticalSystems.png" alt="im_perfectOpticalSystems.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;
The above figure, which is called a &lt;a href="http://www.edmundoptics.com/TechSupport/resource_center/downloads/Anchor-Optics/GraphicalRayTracing.pdf"&gt;ray-trace diagram&lt;/a&gt;, illustrates
what I mean by a perfect imaging system. The system is represented as
a "black box" that collects light coming from a two-dimensional plane
(known as the object plane) and relays the light to another plane
known as the image plane. The whole system is considered to be
rotationally symmetric about a line called the optics axis so that I
can represent it as a two-dimensional sketch instead of requiring a
full, three-dimensional model. Finally, light is modeled as lines with
arrows denoting the direction of propagation &lt;sup&gt;&lt;a id="fnr.4" name="fnr.4" class="footref" href="http://kmdouglass.github.io/posts/paraxial-optics-2-what-problem-does-it-solve.html#fn.4"&gt;4&lt;/a&gt;&lt;/sup&gt;.
&lt;/p&gt;

&lt;p&gt;
Now comes the important point. Within the framework of paraxial optics
theory, it is possible to show that, given an object plane and an
image plane, one can construct an optical system consisting of
components that redirect the light rays in such a way that all the
rays leaving a point in the object plane are brought back together at
a corresponding point in the image plane. &lt;b&gt;This means that the perfect
optical system performs a one-to-one mapping of points in the object&lt;/b&gt;
&lt;b&gt;plane to points in the image plane&lt;/b&gt;. What's more, the distance
between every point in the image plane and the optics axis is
proportional to the distance between their corresponding points and
the axis in the object plane by a constant factor. This factor is
known as the &lt;b&gt;magnification&lt;/b&gt; of the system.
&lt;/p&gt;

&lt;p&gt;
The way this perfect imaging system is realized within the context of
the theory is in the way the components redirect the rays coming from
the object &lt;sup&gt;&lt;a id="fnr.5" name="fnr.5" class="footref" href="http://kmdouglass.github.io/posts/paraxial-optics-2-what-problem-does-it-solve.html#fn.5"&gt;5&lt;/a&gt;&lt;/sup&gt;. What differentiates &lt;i&gt;paraxial&lt;/i&gt; geometrical optics from
plain old geometrical optics is the rules dictating how the
redirection occurs.
&lt;/p&gt;

&lt;p&gt;
One other important point is to consider what happens in imperfect
imaging systems. Once we violate the assumptions of paraxial optics so
that we no longer have a system operating within its range of
validity, we cannot perform a true, one-to-one mapping of points from
the object plane to the image plane. Instead, we find that rays coming
from a single point in the object plane cannot all be brought back
together in any image plane &lt;sup&gt;&lt;a id="fnr.6" name="fnr.6" class="footref" href="http://kmdouglass.github.io/posts/paraxial-optics-2-what-problem-does-it-solve.html#fn.6"&gt;6&lt;/a&gt;&lt;/sup&gt;. We could say that the image plane is
a concept that does not exist outside paraxial optics. And if the
image plane does not exist, how are we to strictly define an image
size and location?
&lt;/p&gt;

&lt;p&gt;
Of course, we can find planes in non-paraxial systems in which there
are pretty good images, and these usually correspond to the image
planes we find by applying the equations and simplifications of
paraxial optics. So paraxial optics is often our first tool for
modeling an imaging system. It tells us roughly where our images will
be formed and how big they are, but it will not tell us about image
quality.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-4" class="outline-2"&gt;
&lt;h2 id="sec-4"&gt;Conclusion&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-4"&gt;
&lt;p&gt;
With this tutorial I hope to have provided you with a conceptual basis
for understanding paraxial geometrical optics without including too
many of its details. I think a conceptual basis such as this is much
better than diving right into ray-trace diagrams with lenses and
mirros. I think new students to optics often wonder what the
importance is of paraxial optics and why it is needed when more
complete optical descriptions exist. I hope that the discussion of the
perfect imaging system and its existence only within the framework of
paraxial geometrical optics helped to clarify its importance.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="footnotes"&gt;
&lt;h2 class="footnotes"&gt;Footnotes: &lt;/h2&gt;
&lt;div id="text-footnotes"&gt;

&lt;div class="footdef"&gt;&lt;sup&gt;&lt;a id="fn.1" name="fn.1" class="footnum" href="http://kmdouglass.github.io/posts/paraxial-optics-2-what-problem-does-it-solve.html#fnr.1"&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;p class="footpara"&gt;
You didn't expect me to give you the answer right away, did
you? :)
&lt;/p&gt;&lt;/div&gt;

&lt;div class="footdef"&gt;&lt;sup&gt;&lt;a id="fn.2" name="fn.2" class="footnum" href="http://kmdouglass.github.io/posts/paraxial-optics-2-what-problem-does-it-solve.html#fnr.2"&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;p class="footpara"&gt;
&lt;a href="http://en.wikipedia.org/wiki/Image"&gt;Even the Wikipedia entry on the concept of an Image&lt;/a&gt; is a bit vague
and philosophical.
&lt;/p&gt;&lt;/div&gt;

&lt;div class="footdef"&gt;&lt;sup&gt;&lt;a id="fn.3" name="fn.3" class="footnum" href="http://kmdouglass.github.io/posts/paraxial-optics-2-what-problem-does-it-solve.html#fnr.3"&gt;3&lt;/a&gt;&lt;/sup&gt; &lt;p class="footpara"&gt;
Maxwell's Fisheye lens is another, but it is a good deal more
complicated and, to my knowledge, has not been demonstrated at optical
wavelengths.
&lt;/p&gt;&lt;/div&gt;

&lt;div class="footdef"&gt;&lt;sup&gt;&lt;a id="fn.4" name="fn.4" class="footnum" href="http://kmdouglass.github.io/posts/paraxial-optics-2-what-problem-does-it-solve.html#fnr.4"&gt;4&lt;/a&gt;&lt;/sup&gt; &lt;p class="footpara"&gt;
It's important to realize that we are modeling the propagation of
light as a ray; we are not saying that light &lt;i&gt;is&lt;/i&gt; a ray. If light
really was a ray and not an electromagnetic wave, then we would not
need the wave theory of optics to explain phenomena like
diffraction. Within the framework of the axioms of geometrical optics,
a ray adequately describes how light propagates.
&lt;/p&gt;&lt;/div&gt;

&lt;div class="footdef"&gt;&lt;sup&gt;&lt;a id="fn.5" name="fn.5" class="footnum" href="http://kmdouglass.github.io/posts/paraxial-optics-2-what-problem-does-it-solve.html#fnr.5"&gt;5&lt;/a&gt;&lt;/sup&gt; &lt;p class="footpara"&gt;
More specifically, it lies in the linearization of Snell's law,
but I won't get into that yet.
&lt;/p&gt;&lt;/div&gt;

&lt;div class="footdef"&gt;&lt;sup&gt;&lt;a id="fn.6" name="fn.6" class="footnum" href="http://kmdouglass.github.io/posts/paraxial-optics-2-what-problem-does-it-solve.html#fnr.6"&gt;6&lt;/a&gt;&lt;/sup&gt; &lt;p class="footpara"&gt;
This phenomenon is precisely what an optical aberration is within
geometrical optics theory.
&lt;/p&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;/div&gt;</description><category>optics</category><category>tutorials</category><guid>http://kmdouglass.github.io/posts/paraxial-optics-2-what-problem-does-it-solve.html</guid><pubDate>Sun, 31 May 2015 13:37:13 GMT</pubDate></item><item><title>Can my laser beam be collimated?</title><link>http://kmdouglass.github.io/posts/can-my-beam-be-collimated.html</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;p&gt;
The fluorescence microscopy setup in my lab requires quite a bit of
power. The minimum irradiance requirement is greater than 1 kW per
square centimeter, and this must cover an area spanning a few tens of
microns across after focusing through the objective. When I was
designing the setup, the highest priority was placed on finding a
cheap laser with as much power as possible at a wavelength of 647 nm;
I considered all other qualities of the laser of secondary importance.
&lt;/p&gt;

&lt;p&gt;
Just like everything else in science, I have learned a very good
lesson from this experience. The laser I decided to purchase is a &lt;a href="http://www.omicron-laser.de/english/lasers/diode-lasers/brixx-lasers/brixx-diode-lasers.html"&gt;800
mW BrixX laser from Omicron&lt;/a&gt;. The cost is under $10,000, which I
consider to be a pretty good deal for the amount of power it puts
out. There is no fiber-coupled version, but all of our lasers are free
space anyway so I did not consider this to be a big problem. The beam
is astigmatic, which is to be expected from a high power laser diode.
&lt;/p&gt;

&lt;p&gt;
The astigmatism is not necessarily a big problem for me, though. What
is surprising to me is how difficult it is to keep the beam &lt;a href="http://en.wikipedia.org/wiki/Collimated_light"&gt;collimated&lt;/a&gt;
over large distances, that is, to keep it roughly the same size as it
propagates. My application requires a fairly small beam size since the
exit pupil of the objective is only 6 millimeters in diameter. With
&lt;a href="http://en.wikipedia.org/wiki/M_squared"&gt;M-squared&lt;/a&gt; values direct from the laser of 12 and 25, it is quite
difficult to keep the beam collimated for a long enough distance to
steer the beam through all the optics and to keep it small enough to
prevent overfilling the objective's exit pupil and losing power.
&lt;/p&gt;

&lt;p&gt;
What I have learned from this is that free-space diode lasers, and
more generally multimode laser beams, require extra consideration to
ensure that they will stay collimated in long setups.
&lt;/p&gt;

&lt;p&gt;
So, how can I predict the distance over which my beam can stay
collimated to better judge how well it will work for my setup? The
first thing to realize is that no beam can stay collimated
forever. Real laser beams experience diffraction, which causes them to
spread as they propagate. This means that the first thing I should do
is to consider the distances spanned by the beam paths. In a
microscopy setup, this path will probably not be longer than a couple
meters. In mine, it's roughly two meters since I am combining a number
of laser beams together and need the extra space.
&lt;/p&gt;

&lt;p&gt;
Once I identify the length scale over which the beam should stay
collimated, I need to examine the beam parameter that is best
associated with collimation. For a pure Gaussian beam, this parameter
is the &lt;a href="http://en.wikipedia.org/wiki/Rayleigh_length"&gt;Rayleigh range&lt;/a&gt;. The Rayleigh range is the distance between the
beam waist and the point where the cross-sectional area of the beam
has doubled, or, equivalently, to the point where the radius of the
beam has increased over the waist radius by a factor of the
\(\sqrt{2}\). For a pure Gaussian beam with a waist radius of \(w_0\) and
a wavelength of \(\lambda\), the Rayleigh range is given by the equation
&lt;/p&gt;


\begin{equation*}
z_R = \frac{\pi w_0^2}{\lambda}
\end{equation*}

&lt;p&gt;
It is represented by the symbol &lt;i&gt;z&lt;sub&gt;R&lt;/sub&gt;&lt;/i&gt; in the figure below from
Wikipedia. The total distance over which the beam will stay collimated
is represented by &lt;i&gt;b&lt;/i&gt; and is just twice the Rayleigh range.
&lt;/p&gt;

&lt;div align="center"&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="http://kmdouglass.github.io/GaussianBeamWaist.png" alt="GaussianBeamWaist.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;
The Rayleigh range of a Gaussian laser beam should therefore be larger
than the characteristic distance of my setup that I identified in the
previous step. But what about multimode beams like the one from my
laser diode? This is where the concept of an "embedded Gaussian" comes
into play. (For more information about this idea, see &lt;a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.177.3400&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;this tutorial by
Tony Siegman&lt;/a&gt;.) I can predict the collimated distance by computing the
Rayleigh range of an ideal Gaussian beam, and then divide it by the
M&lt;sup&gt;2&lt;/sup&gt; parameter for the beam.
&lt;/p&gt;

&lt;p&gt;
Let's take an example using numbers from my own laser. I will first
pretend there are no collimating optics in the laser, which is not
true but will serve as a good example as to why diode lasers without
collimating optics are not good for free space setups. From the
laser's spec sheet, I know that the M&lt;sup&gt;2&lt;/sup&gt; value in the ``bad'' direction
is 25 and that its waist size, which is probably half the size of the
diode in one principle direction, is 107 microns. Using the above
equation, I get a value of 56 centimeters, which means that an ideal
Gaussian beam with these specs will stay collimated over about half a
meter.
&lt;/p&gt;

&lt;p&gt;
However, my real multimode beam will have a Rayleigh range that is
smaller than this value by a factor of 25, which is only about 2
centimeters. For this reason, diode laser beams almost always have
collimating optics; the beam from the diode itself is highly
divergent.
&lt;/p&gt;

&lt;p&gt;
Returning to my own setup, if I resize the beam using a telescope to
have a waist radius of 2 millimeters so it almost entirely fits inside
the objective's exit pupil, the Rayleigh range of the embedded
Gaussian beam will be almost &lt;i&gt;20 meters&lt;/i&gt;, which is pretty long. The
real beam, however, will have a Rayleigh range of about 780
millimeters meters due to the high M&lt;sup&gt;2&lt;/sup&gt; value. &lt;b&gt;Practically, this means
I have about one meter of collimated laser beam&lt;/b&gt; with which to work
since I have double the Rayleigh range of collimated distance, but
really I want the beam to travel less distance than this.
&lt;/p&gt;

&lt;p&gt;
Fortunately I can shrink the beam path enough that this should not be
a problem, but it does serve as a very good lesson when looking for
lasers for a microscopy application.
&lt;/p&gt;</description><category>microscopy</category><category>optics</category><guid>http://kmdouglass.github.io/posts/can-my-beam-be-collimated.html</guid><pubDate>Mon, 04 May 2015 07:44:42 GMT</pubDate></item><item><title>Relearning paraxial optics</title><link>http://kmdouglass.github.io/posts/relearning-paraxial-optics.html</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;p&gt;
As a microscopist who designs and builds custom microscopes, I often
find that first order ray tracing is one of the most useful tools I
have. It is most useful to me when I am starting a design or for
checking that I have not made any serious logical blunders when
working at the bench. I also find it to be a good teaching tool and
excellent for communicating my designs to others.
&lt;/p&gt;

&lt;p&gt;
Since I have recently made a lot of back-of-the-envelope ray trace
designs for a microscope I am building at work, I have begun to
critically think about why ray tracing works so well and how it fits
inside the structure of the physical theories of optics.
&lt;/p&gt;

&lt;p&gt;
Ray tracing is a technique derived from &lt;b&gt;paraxial geometrical optics&lt;/b&gt;
and really is just a consequence of the axioms and assumptions in the
development of the theory. When I think back to when I first learned
about paraxial optics, however, I am reminded of severe assumptions
that place limits on the scope of its validity. So how can a theory
that makes such an enormous simplification by treating the
electromagnetic waves described by Maxwell's equations as lines
obeying the rules of geometry still be so useful?
&lt;/p&gt;

&lt;p&gt;
In this next series of blog posts, I want to explore this question and
take the time to relearn paraxial optics with the benefit of
hindsight. Physicists typically learn paraxial optics as their first
theory of optics because it is relatively easy as compared to
electromagnetism and quantum optics. I am curious what aspects of the
theory I can appreciate now that I am familiar with the more advanced
optical theories.
&lt;/p&gt;

&lt;p&gt;
The picture below might also provide a bit of motivation for why this
interests me: we physicists learn about optics theories in a direction
of increasing complexity during our education. However, this approach
also means that we learn the most general theories last, so it is not
obvious why assumptions and approximations are made in the theories we
learn first. The result, I think, leads to a bit of logical
discordance in our minds that can prevent a clear understanding of the
subject. With this series of posts I hope to remove this cognitive
dissonance and improve my understanding of the field I work in.
&lt;/p&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="http://kmdouglass.github.io/order_of_optics_theories.png" alt="order_of_optics_theories.png"&gt;
&lt;/p&gt;
&lt;/div&gt;</description><category>optics</category><category>tutorials</category><guid>http://kmdouglass.github.io/posts/relearning-paraxial-optics.html</guid><pubDate>Sun, 19 Apr 2015 09:05:21 GMT</pubDate></item><item><title>Reading select lines from a text file</title><link>http://kmdouglass.github.io/posts/reading-select-lines-from-a-text-file.html</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;p&gt;
&lt;a href="https://gist.github.com/kmdouglass/507717d339bc82f850ce"&gt;I just created a Python Gist&lt;/a&gt; for reading select lines from a text file
into memory. I came up with this Gist when I needed to parse the core
log from our &lt;a href="https://www.micro-manager.org/"&gt;microscope control software (Micro-Manager)&lt;/a&gt;. One of our
devices was continously sending its statistics to the computer, which
would then be recorded to the log. I wanted to find only lines that
contained the statistics by searching for the &lt;b&gt;STATS&lt;/b&gt; identifier,
which was unique to these lines.
&lt;/p&gt;

&lt;p&gt;
The problem was a bit more difficult than reading just the lines
containing this string because I wanted the statistics only for times
when the software was acquiring a time series of images. Luckily, the
core log also contains lines with unique strings indicating when a
time series was initiated and stopped. All lines in the log are
time-stamped.
&lt;/p&gt;

&lt;p&gt;
Below is the Gist I used to solve this problem. The lines that will be
retained in memory will contain the strings in the list lineFilters. I
then define a function named stringIsIn that will return a list of
bool indicating whether each string is present in the line.
&lt;/p&gt;

&lt;p&gt;
At the bottom of the Gist, I use a list comprehension to loop over
each line in the file. The line is appended to a growing list called
outputLines if the line contains &lt;i&gt;any&lt;/i&gt; of the strings I defined. Note
that it's not necessary to use a separate definition for stringIsIn;
the list comprehension over lineFilters could have been placed inline
with the primary list comprension over lines in the file. I do think
it is more readable the way it is presented below, however.
&lt;/p&gt;

&lt;p&gt;
I welcome any comments or suggestions, especially on the &lt;a href="https://gist.github.com/kmdouglass/507717d339bc82f850ce"&gt;Gist website&lt;/a&gt;
where others may be more likely to find it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;filename&lt;/span&gt;    &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;'myFile.txt'&lt;/span&gt;
&lt;span class="n"&gt;outputLines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

&lt;span class="c"&gt;# Keep all lines containing ANY of the following list of strings.&lt;/span&gt;
&lt;span class="n"&gt;lineFilters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;'line 1'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s"&gt;'line 2'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s"&gt;'line 3'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;stringIsIn&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;filter&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nb"&gt;filter&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;lineFilters&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;


&lt;span class="c"&gt;# Read only lines containing one of the strings into memory.&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;'r'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;outputLines&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;file&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;any&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stringIsIn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><category>micro-manager</category><category>python</category><guid>http://kmdouglass.github.io/posts/reading-select-lines-from-a-text-file.html</guid><pubDate>Wed, 18 Mar 2015 07:27:50 GMT</pubDate></item><item><title>The basics of virtualenv</title><link>http://kmdouglass.github.io/posts/the-basics-of-virtualenv.html</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;p&gt;
I use Python 3.4 in most of my data analyses and in some
simulations. I like a lot of its features, like its implementation of
generators, maps, and filters. However, much of the software on my
Debian Wheezy system depends on Python 2.7 to run, such as
&lt;a href="http://www.mendeley.com/"&gt;Mendeley&lt;/a&gt;. (It used to run just fine with Python 3.4, until I ran an
automatic update and that was the end of that.)
&lt;/p&gt;

&lt;p&gt;
To run some Python 2.7 programs, I used to do the following:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;sudo rm /usr/bin/python 
sudo ln -s /usr/bin/python2.7 /usr/bin/python
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
I know. Ouch. Every single time I needed to run a program that
depended on python2.7, I would delete the symlink in /usr/bin, make a
new link to python2.7, and then run my program. When I needed to give
various programs convenient access to python3.4, I would delete the
symlink and create a new one to the newer version.
&lt;/p&gt;

&lt;p&gt;
This was dumb, because there is a convenient Python-based tool that
can fix the problem of needing multiple versions of Python (and
libraries!) on the same system. The solution to this problem is called
&lt;a href="https://virtualenv.pypa.io/en/latest/"&gt;virtualenv&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
There are a lot of descriptions about what virtualenv is on the
internet, so I won't bother going into details here. Instead, I will
focus on just the very basics of its setup and use so that I can have
a handy future reference for when I forget how something works and so
that others can profit from what I have learned. Most everything I've
done came from &lt;a href="http://docs.python-guide.org/en/latest/"&gt;python-guide.org&lt;/a&gt;, so I'm more-or-less putting &lt;a href="http://docs.python-guide.org/en/latest/dev/virtualenvs/"&gt;what they
have already said&lt;/a&gt; into my own words.
&lt;/p&gt;

&lt;p&gt;
To start, I already have Python 2.7 and 3.4 installed on my system. In
principle, you do not need them installed at the system level, but I
already have done this so I will start from there. I first installed
pip for Python 2.7 since I only had pip3 on my system to start. I did
this because I want to keep Python 2.7 as my system's default Python
environment.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;sudo apt-get update
sudo apt-get install python-pip
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Once installed, I used it to install virtualenv and
&lt;a href="https://virtualenvwrapper.readthedocs.org/en/latest/"&gt;virtualenvwrapper&lt;/a&gt;. The latter provides some nice features for working
with virtualenv.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;sudo pip install virtualenv
sudo pip install virtualenvwrapper
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now, virtualenvwrapper requires an environment variable to tell it
where to store the folders for each virtual environment. This
environment variable is called WORKON_HOME. First, I created the
folder it will point to:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;mkdir ~/Envs
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Next, I edited my ~/.bashrc and added the following line:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;WORKON_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;~/Envs
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
All of my virtual environment files (except for the Python
intepreters) will be stored in this folder. Finally, I restarted my
terminal window so that the environment variable was assigned. You can
check this by typing &lt;code&gt;echo $WORKON_HOME&lt;/code&gt; in your new terminal
window. If it returns the path to your new environments folder, then
you should be fine.
&lt;/p&gt;

&lt;p&gt;
Next, I ran the virtualwrapper setup script. Note that I did not need
sudo (in fact, sudo could not find a command called ``source'') and
that no output is returned when the script is run.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;source&lt;/span&gt; /usr/local/bin/virtualenvwrapper.sh
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now virtualenvwrapper should be installed, so let's make a virtual
environment. We can do this using the &lt;code&gt;mkvirtualenv&lt;/code&gt; command, followed
by a name for the environment. I will use the name ``venv'' in this
example, like Kenneth Reitz did in his guide that I linked above.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;mkvirtualenv venv
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
To start the new virtual environment, type &lt;code&gt;workon venv&lt;/code&gt; and note that
change in the prompt, indicating which environment you are in. You now
have a fresh Python environment to which you can add any library you
wish. To leave the environment, type &lt;code&gt;deactivate&lt;/code&gt; into your terminal.
&lt;/p&gt;

&lt;p&gt;
One simple test that you can do to see whether your Python environment
really is clean is to run the Python interpreter from inside your
environment and try importing a module that you know is in your
system-wide site packages but not in your virtual environment. For
example, inside venv I type &lt;code&gt;python&lt;/code&gt; at the terminal prompt and tried
importing numpy, which I had not yet installed in venv:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This returned an &lt;b&gt;ImportError: No module named numpy&lt;/b&gt;. Since I do have
numpy installed on my system but not in this environment, it tells me
that the environment is likely clean.
&lt;/p&gt;

&lt;p&gt;
To install new libraries, simply use pip or install them to the folder
that was created for this environment in ~/Env. To delete a virtual
environment entirely, use &lt;code&gt;rmvirtual env&lt;/code&gt;.
&lt;/p&gt;

&lt;p&gt;
Now, how can I specify that I want the virtual environment to use the
python3.4 interpreter in a virtual environment named
``python3-general''? Doing so would solve my original problem. Simply
make a new virtual environment like so:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;mkvirtualenv&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nb"&gt;bin&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;python3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="n"&gt;python3&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;general&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Voilà. C'est tout. I hope this helps you get up and running with this
great tool!
&lt;/p&gt;</description><category>python</category><guid>http://kmdouglass.github.io/posts/the-basics-of-virtualenv.html</guid><pubDate>Tue, 10 Feb 2015 06:47:50 GMT</pubDate></item><item><title>Sending arguments to Python decorators</title><link>http://kmdouglass.github.io/posts/sending-arguments-to-python-decorators.html</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;p&gt;
&lt;a href="http://simeonfranklin.com/blog/2012/jul/1/python-decorators-in-12-steps/"&gt;Python's decorators&lt;/a&gt; are tools for changing the behavior of a function
without completely recoding it. When we apply a decorator to a
function, we say that the function has been decorated. Strictly
speaking, when we decorate a function, we send it to a wrapper that
returns another function. It's as simple as that.
&lt;/p&gt;

&lt;p&gt;
I was having trouble understanding exactly to which function, the
original or the decorated one, the arguments are sent in a Python
decorated function call. I wrote the following script to better
understand this process (I use Python 3.4):
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;wrapper&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inFunction&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;outFunction&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
	&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'The input arguments were:'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
	&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
	    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;&lt;span class="si"&gt;%r&lt;/span&gt;&lt;span class="s"&gt; : &lt;/span&gt;&lt;span class="si"&gt;%r&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

	&lt;span class="c"&gt;# Return the original function&lt;/span&gt;
	&lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;inFunction&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;outFunction&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
&lt;code&gt;wrapper(inFunction)&lt;/code&gt; is a function that accepts another function as
an argument. It returns a function that simply prints the keyword
arguments of &lt;i&gt;inFunction()&lt;/i&gt;, and calls &lt;i&gt;inFunction()&lt;/i&gt; like normal.
&lt;/p&gt;

&lt;p&gt;
To decorate the function &lt;i&gt;add(x = 1, y = 2)&lt;/i&gt; so that its arguments are
printed without recoding it, we normally would place &lt;code&gt;@wrapper&lt;/code&gt; before
its definition. However, let's make the decorator in a way that's
closer to how &lt;i&gt;@&lt;/i&gt; works under the hood:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;In [22]: decoratedAdd = wrapper(add)
In [23]: decoratedAdd(x = 1, y = 24)
The input arguments were:
'y' : 24
'x' : 1
Out[23]: 25
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
When we call &lt;i&gt;decoratedAdd(x = 1, y = 24)&lt;/i&gt;, the arguments are printed
to the screen and we still get the same functionality of &lt;i&gt;add()&lt;/i&gt;. What
I wanted to know was this: are the keyword arguments x = 1, y = 24
bound in the namespace of &lt;i&gt;wrapper()&lt;/i&gt; or in the namespace of
&lt;i&gt;outFunction()&lt;/i&gt;? &lt;b&gt;In otherwords, does &lt;i&gt;wrapper()&lt;/i&gt; at any point know
what the arguments are that I send to the decorated function?&lt;/b&gt;
&lt;/p&gt;

&lt;p&gt;
The answer, as it turns out, is no in this case. This is because the
&lt;i&gt;wrapper()&lt;/i&gt; function first returns the decorated function, and then
the arguments are passed into the decorated function. If this order of
operations were flipped, &lt;i&gt;wrapper()&lt;/i&gt; should know that I set x to 1 and
y to 24, but really it doesn't know these details at all.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;In [24]: wrapper(add)(x = 1, y = 24)
The input arguments were:
'y' : 24
'x' : 1
Out[24]: 25
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
So, when I call &lt;i&gt;wrapper(add)(x = 1, y = 24)&lt;/i&gt;, first &lt;i&gt;wrapper(add)&lt;/i&gt; is
called, which returns &lt;i&gt;outFunction()&lt;/i&gt;, and then these arguments are
passed to &lt;i&gt;outFunction()&lt;/i&gt;.
&lt;/p&gt;

&lt;p&gt;
Now what happens when I call &lt;code&gt;wrapper(add(x = 1, y = 24))&lt;/code&gt;? When I try
this, the arguments are first passed into add, but then &lt;i&gt;outFunction&lt;/i&gt;
is returned without any arguments applied to it.
&lt;/p&gt;

&lt;p&gt;
This example can give us an idea about the working order of operations
in Python. Here, this example reveals that function calls in Python
are left-associative.
&lt;/p&gt;</description><category>python</category><guid>http://kmdouglass.github.io/posts/sending-arguments-to-python-decorators.html</guid><pubDate>Sat, 24 Jan 2015 07:45:38 GMT</pubDate></item><item><title>Overcoming complexity in biology</title><link>http://kmdouglass.github.io/posts/overcoming-complexity-in-biology.html</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;p&gt;
I've been sitting in on a short lecture series presented by &lt;a href="http://markolab.bmbcb.northwestern.edu/marko/"&gt;Prof. John
Marko&lt;/a&gt; here at the EPFL. The topic is on the biophysics of DNA and
covers what is probably at least a 25 year span of research that has
emerged on its mechanical and biochemical properties.
&lt;/p&gt;

&lt;p&gt;
DNA amazes me in two different ways: relatively simple physical
theories can explain &lt;i&gt;in vitro&lt;/i&gt; experiments, but establishing a
complete understanding of the behavior of DNA and its associated
proteins (collectively known as chromatin) &lt;i&gt;in vivo&lt;/i&gt; seems at this
point almost hopeless.
&lt;/p&gt;

&lt;p&gt;
So why do I think it's so difficult to establish a complete physical
theory of the nucleus?
&lt;/p&gt;

&lt;p&gt;
Certainly a lot of recent research has helped us to understand parts
of what happens inside the nucleus. Take for example recent
experiments that look at &lt;a href="http://en.wikipedia.org/wiki/Transcription_factor#Accessibility_of_DNA-binding_site"&gt;transcription factor&lt;/a&gt; (TF) binding and the
nuclear architecture. TF binding experiments have helped us understand
the mechanism of how a single transcription factor ``searches'' for a
target site on a chromosome. It undergoes diffusion in the crowded
nuclear environment, occasionally binding to the DNA non-specifically
and sliding along it. We now know that this combined diffusion/sliding
mechanism produces an optimum search strategy.
&lt;/p&gt;

&lt;p&gt;
Studies of nuclear architecture attempt to understand how the long DNA
polymer, which is on the order of &lt;i&gt;one meter&lt;/i&gt; long, is packaged into
the nucleus, which is only about &lt;i&gt;five micrometers&lt;/i&gt; in diameter. This
is nearly six orders of magnitude of compaction. Some current theories
treat the DNA as a hierarchically packaged polymer or a fractal
structure. Interestingly, the fractal model can &lt;a href="http://www.ncbi.nlm.nih.gov/pubmed/24380602"&gt;explain why TF's may
diffuse optimally&lt;/a&gt; and when crowding can hinder their search.
&lt;/p&gt;

&lt;p&gt;
Both of these examples represent a generalization of one particular
phenomenon that occurs inside the nucleus. And even given the enormity
of these works, I think this generalization can be dubious because it
may not apply to all cell types and there may be differences between
cultured cells and those found in an actual organism.
&lt;/p&gt;

&lt;p&gt;
The problem in capturing complete physical models of the nucleus seems
to lie with the philosophy of physics itself: find the most essential
parts of the system and include those in your model, discarding all
irrelevant details. Unfortunately, &lt;i&gt;in vitro&lt;/i&gt; experiments suggest that
every detail seems to matter inside the nucleus. Local salt
concentrations effect electrostatic interactions and entropic binding
between proteins and DNA, the global nuclear architecture has an
effect on single TF's diffusing inside the nucleus, there are a huge
number of proteins that associate with DNA and control the
conformation in &lt;a href="http://www.ncbi.nlm.nih.gov/pubmed/22495300"&gt;toplogically associating domains&lt;/a&gt;. The list goes on and
on.
&lt;/p&gt;

&lt;p&gt;
A common theme to this list that I have described above is that
phenomena at one length scale tend to have a direct impact on those at
another, like the global nuclear architecture affecting a single TF
trajectory. These are hallmarks of complexity: a dependence on the
details of a system and multiscale behavior.
&lt;/p&gt;

&lt;p&gt;
I am currently of the opinion that a complete model of the nucleus,
and probably of other biological systems, must therefore necessarily
abandon one important part of physical theories: reduction to the
simplest possible set of parameters to describe a system. We need to
incorporate all the details across all length scales to reproduce what
exactly is going on.
&lt;/p&gt;

&lt;p&gt;
And if classical physics falls short of this goal, what other
approaches do we then require?
&lt;/p&gt;</description><category>biology</category><category>biophysics</category><category>complexity</category><guid>http://kmdouglass.github.io/posts/overcoming-complexity-in-biology.html</guid><pubDate>Wed, 21 Jan 2015 07:16:04 GMT</pubDate></item><item><title>Learning Python's Multiprocessing Module</title><link>http://kmdouglass.github.io/posts/learning-pythons-multiprocessing-module.html</link><dc:creator>Kyle M. Douglass</dc:creator><description>&lt;p&gt;
I've been doing a bit of programming work lately that would greatly
benefit from a speed boost using parallel/concurrent processing
tools. Essentially, I'm doing a &lt;a href="http://www.mathworks.com/help/simulink/examples/parallel-simulations-using-parfor-parameter-sweep-in-normal-mode.html"&gt;parameter sweep&lt;/a&gt; where the values for
two different simulation parameters are input into the simulation and
allowed to run with the results being recorded to disk at the end. The
point is to find out how the simulation results vary with the
parameter values.
&lt;/p&gt;

&lt;p&gt;
In my current code, a new simulation is initialized with each pair of
parameter values inside one iteration of a for loop; each iteration of
the loop is independent of the others. Spreading these iterations over
the 12 cores on my workstation should result in about a 12x decrease
in the amount of time the simulation takes to run.
&lt;/p&gt;

&lt;p&gt;
I've had good success using the &lt;code&gt;parfor&lt;/code&gt; loop construct in Matlab in
the past, but my simulation was written in Python and I want to learn
more about Python's multiprocessing tools, so this post will explore
that module in the context of performing parameter sweeps.
&lt;/p&gt;

&lt;div id="outline-container-sec-1" class="outline-2"&gt;
&lt;h2 id="sec-1"&gt;Profile the code first to identify bottlenecks&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-1"&gt;
&lt;p&gt;
First, I profiled my code to identify where any slowdowns might be
occurring in the serial program. I used a great tutorial at the &lt;a href="https://zapier.com/engineering/profiling-python-boss/"&gt;Zapier
Engineering&lt;/a&gt; blog to write a decorator for profiling the main instance
method of my class that was doing most of the work. Surprisingly, I
found that a few numpy methods were taking the most time, namely
&lt;b&gt;norm()&lt;/b&gt; and &lt;b&gt;cross()&lt;/b&gt;. To address this, I directly imported the
Fortran BLAS &lt;b&gt;nrm2()&lt;/b&gt; function using scipy's &lt;b&gt;get_blas_funcs()&lt;/b&gt;
function and hard-coded the cross product in pure Python inside the
method; these two steps alone resulted in a 4x decrease in simulation
time. I suspect the reason for this was because the overhead of
calling functions on small arrays outweighs the increase in speed
using Numpy's optimized C code. I was normalizing single vectors and
taking cross products between two vectors at a time many times during
each loop iteration.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-2" class="outline-2"&gt;
&lt;h2 id="sec-2"&gt;A brief glance at Python's multiprocessing module&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-2"&gt;
&lt;p&gt;
&lt;a href="http://pymotw.com/2/multiprocessing/basics.html"&gt;PyMOTW&lt;/a&gt; has a good, minimal description of the main aspects of the
multiprocessing module. They state that the simplest way to create
tasks on different cores of a machine is to create new &lt;b&gt;Process&lt;/b&gt;
objects with target functions. Each object is then set to execute by
calling its &lt;b&gt;start()&lt;/b&gt; method.
&lt;/p&gt;

&lt;p&gt;
The basic example from their site looks like this:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;multiprocessing&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;worker&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;"""worker function"""&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;'Worker'&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;jobs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
	&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;multiprocessing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;worker&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
	&lt;span class="n"&gt;jobs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
	&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
In this example, it's important to create the Process instances inside
the
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
section of the script because child processes import the script where
the target function is contained. Placing the object instantiation in
this section prevents an infinite, recursive string of such
instantiations. A workaround to this is to define the function in a
different script and import it into the namespace.
&lt;/p&gt;

&lt;p&gt;
To send arguments to the function (&lt;b&gt;worker()&lt;/b&gt; in the example above),
we can use the &lt;b&gt;args&lt;/b&gt; keyword in the Process object instantiation like
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;p = multiprocessing.Process(target=worker, args=(i,))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
A very important thing to note is that the arguments must be objects
that can be pickled using Python's pickle module. If an argument is a
class instance, this means that every attritube of that class must be
pickleable.
&lt;/p&gt;

&lt;p&gt;
An important class in the multiprocessing module is a &lt;b&gt;Pool&lt;/b&gt;. A &lt;a href="https://docs.python.org/3.4/library/multiprocessing.html#multiprocessing.pool.Pool"&gt;Pool&lt;/a&gt;
object controls a pool of worker processes. Jobs can be submitted to
the Pool, which then sends the jobs to the individual workers.
&lt;/p&gt;

&lt;p&gt;
The &lt;b&gt;Pool.map()&lt;/b&gt; achieves the same functionality as Matlab's &lt;b&gt;parfor&lt;/b&gt;
construct. This method essentially applies a function to each element
in an iterable and returns the results. For example, if I wanted to
square each number in a list of integers between 0 and 9 and perform
the square operation on multiple processors, I would write a function
for squaring an argument, and supply this function and the list of
integers to &lt;b&gt;Pool.map()&lt;/b&gt;. The code looks like this:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;multiprocessing&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;funSquare&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;pool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;multiprocessing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Pool&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;funSquare&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-3" class="outline-2"&gt;
&lt;h2 id="sec-3"&gt;Design the solution to the problem&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-3"&gt;
&lt;p&gt;
In my parameter sweep, I have two classes: one is an object that I'm
simulating and the other acts as a controller that sends parameters to
the structure and collects the results of the simulation. Everything
was written in a serial fashion and I want to change it so the bulk of
the work is performed in parallel.
&lt;/p&gt;

&lt;p&gt;
After the bottlenecks were identified in the serial code, I began
thinking about how the the problem of parameter sweeps could be
addressed using the multiprocessing module.
&lt;/p&gt;

&lt;p&gt;
The solution requirements I identified for my parameter sweep are as
follows:
&lt;/p&gt;

&lt;ol class="org-ol"&gt;
&lt;li&gt;Accept two values (one for each parameter) from the range of values
to test as inputs to the simulation.
&lt;/li&gt;
&lt;li&gt;For each pair of values, run the simulation as an independent
process.
&lt;/li&gt;
&lt;li&gt;Return the results of the simulation as as a list or Numpy array.
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;
I often choose to return the results as Numpy arrays since I can
easily pickle them when saving to a disk. This may change depending on
your specific problem.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-4" class="outline-2"&gt;
&lt;h2 id="sec-4"&gt;Implementation of the solution&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-4"&gt;
&lt;p&gt;
I'll now give a simplified example of how this solution to the
parameter sweep can be implemented using Python's multiprocessing
module. I won't use objects like in my real code, but will first
demonstrate an example where &lt;b&gt;Pool.map()&lt;/b&gt; is applied to a list of
numbers.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;multiprocessing&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;runSimulation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""This is the main processing function. It will contain whatever&lt;/span&gt;
&lt;span class="sd"&gt;    code should be run on multiple processors.&lt;/span&gt;

&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="n"&gt;param1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;param2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;
    &lt;span class="c"&gt;# Example computation&lt;/span&gt;
    &lt;span class="n"&gt;processedData&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;ctr&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
	&lt;span class="n"&gt;processedData&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;param1&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;ctr&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;param2&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;processedData&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c"&gt;# Define the parameters to test&lt;/span&gt;
    &lt;span class="n"&gt;param1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;param2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;202&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c"&gt;# Zip the parameters because pool.map() takes only one iterable&lt;/span&gt;
    &lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;param1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;param2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;pool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;multiprocessing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Pool&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;runSimulation&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This is a rather silly example of a simulation, but I think it
illustrates the point nicely. In the &lt;b&gt;&lt;span class="underline"&gt;&lt;span class="underline"&gt;main&lt;/span&gt;&lt;/span&gt;&lt;/b&gt; portion of the code, I
first define two lists for each parameter value that I want to
'simulate.' These parameters are zipped together in this example
because &lt;b&gt;Pool.map()&lt;/b&gt; takes only one iterable as its argument. The pool
is opened using with &lt;b&gt;multiprocessing.Pool()&lt;/b&gt;.
&lt;/p&gt;

&lt;p&gt;
Most of the work is performed in the function
&lt;b&gt;runSimulation(params)&lt;/b&gt;. It takes a tuple of two parameters which are
unpacked. Then, these parameters are used in the for loop to build a
list of simulated values which is eventually returned.
&lt;/p&gt;

&lt;p&gt;
Returning to the &lt;b&gt;&lt;span class="underline"&gt;&lt;span class="underline"&gt;main&lt;/span&gt;&lt;/span&gt;&lt;/b&gt; section, each simulation is run on a
different core of my machine using the &lt;b&gt;Pool.map()&lt;/b&gt; function. This
applies the function called &lt;b&gt;runSimulation()&lt;/b&gt; to the values in the
&lt;b&gt;params&lt;/b&gt; iterable. In other words, it calls the code described in
&lt;b&gt;runSimulation()&lt;/b&gt; with a different pair of values in params.
&lt;/p&gt;

&lt;p&gt;
All the results are eventually returned in a list in the same order as
the parameter iterable. This means that the first element in the
&lt;b&gt;results&lt;/b&gt; list corresponds to parameters of 0 and 2 in this example.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-5" class="outline-2"&gt;
&lt;h2 id="sec-5"&gt;Iterables over arbitrary objects&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-5"&gt;
&lt;p&gt;
In my real simulation code, I use a class to encapsulate a number of
structural parameters and methods for simulating a polymer model. So
long as instances of this class can be &lt;a href="https://docs.python.org/3/library/pickle.html"&gt;pickled&lt;/a&gt;, I can use them as the
iterable in &lt;b&gt;Pool.map()&lt;/b&gt;, not just lists of floating point numbers.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;multiprocessing&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;simObject&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
	&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;param1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;param2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;runSimulation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;objInstance&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""This is the main processing function. It will contain whatever&lt;/span&gt;
&lt;span class="sd"&gt;    code should be run on multiple processors.&lt;/span&gt;

&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="n"&gt;param1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;param2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;objInstance&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;param1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;objInstance&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;param2&lt;/span&gt;
    &lt;span class="c"&gt;# Example computation&lt;/span&gt;
    &lt;span class="n"&gt;processedData&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;ctr&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
	&lt;span class="n"&gt;processedData&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;param1&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;ctr&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;param2&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;processedData&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c"&gt;# Define the parameters to test&lt;/span&gt;
    &lt;span class="n"&gt;param1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;param2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;202&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;objList&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="c"&gt;# Create a list of objects to feed into pool.map()&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p2&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;param1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;param2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
	&lt;span class="n"&gt;objList&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;simObject&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;p1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p2&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

    &lt;span class="n"&gt;pool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;multiprocessing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Pool&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;runSimulation&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;objList&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Again, this is a silly example, but it demonstrates that lists of
objects can be used in the parameter sweep, allowing for easy
parallelization of object-oriented code.
&lt;/p&gt;

&lt;p&gt;
Instead of &lt;b&gt;runSimulation()&lt;/b&gt;, you may want to apply an instance method
to a list in &lt;b&gt;pool.map()&lt;/b&gt;. A naïve way to do this is to replace
&lt;b&gt;runSimulation&lt;/b&gt; with with the method name but this too causes
problems. I won't go into the details here, but one solution is to use
an instance's &lt;b&gt;__call__()&lt;/b&gt; method and pass the object instance into
the pool. More details can be found &lt;a href="http://stackoverflow.com/questions/1816958/cant-pickle-type-instancemethod-when-using-pythons-multiprocessing-pool-ma"&gt;here&lt;/a&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-6" class="outline-2"&gt;
&lt;h2 id="sec-6"&gt;Comparing computation times&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-6"&gt;
&lt;p&gt;
The following code makes a rough comparison between computation time
for the parallel and serial versions of &lt;b&gt;map()&lt;/b&gt;:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;multiprocessing&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;runSimulation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""This is the main processing function. It will contain whatever&lt;/span&gt;
&lt;span class="sd"&gt;    code should be run on multiple processors.&lt;/span&gt;

&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="n"&gt;param1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;param2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;
    &lt;span class="c"&gt;# Example computation&lt;/span&gt;
    &lt;span class="n"&gt;processedData&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;ctr&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
	&lt;span class="n"&gt;processedData&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;param1&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;ctr&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;param2&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;processedData&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c"&gt;# Define the parameters to test&lt;/span&gt;
    &lt;span class="n"&gt;param1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;param2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;202&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;param1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;param2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;pool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;multiprocessing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Pool&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c"&gt;# Parallel map&lt;/span&gt;
    &lt;span class="n"&gt;tic&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;runSimulation&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;toc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c"&gt;# Serial map&lt;/span&gt;
    &lt;span class="n"&gt;tic2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;runSimulation&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;toc2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'Parallel processing time: &lt;/span&gt;&lt;span class="si"&gt;%r&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;Serial processing time: &lt;/span&gt;&lt;span class="si"&gt;%r&lt;/span&gt;&lt;span class="s"&gt;'&lt;/span&gt;
	  &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;toc&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;tic&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;toc2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;tic2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
On my machine, &lt;b&gt;pool.map()&lt;/b&gt; ran in 9.6 seconds, but the serial version
took 163.3 seconds. My laptop has 8 cores, so I would have expected
the speedup to be a factor of 8, not a factor of 16. I'm not sure why
it's 16, but I suspect part of the reason is that measuring system
time using the &lt;b&gt;time.time()&lt;/b&gt; function is not wholly accurate.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-7" class="outline-2"&gt;
&lt;h2 id="sec-7"&gt;Important points&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-7"&gt;
&lt;p&gt;
I can verify that all the cores are being utilized on my machine while
the code is running by using the &lt;a href="http://hisham.hm/htop/"&gt;htop&lt;/a&gt; console program. In some cases,
Python modules like Numpy, scipy, etc. may limit processes in Python
to running on only one core on Linux machines, which defeats the
purpose of writing concurrent code in this case. (See for example &lt;a href="http://stackoverflow.com/questions/15639779/what-determines-whether-different-python-processes-are-assigned-to-the-same-or-d/15641148#15641148"&gt;this
discussion&lt;/a&gt;.) To fix this, we can import Python's &lt;b&gt;os&lt;/b&gt; module to reset
the task affinity in our code:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"taskset -p 0xff &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getpid&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-8" class="outline-2"&gt;
&lt;h2 id="sec-8"&gt;Conclusions&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-8"&gt;
&lt;p&gt;
I think that Matlab's &lt;b&gt;parfor&lt;/b&gt; construct is easier to use because one
doesn't have to consider the nuances of writing concurrent code. So
long as each loop iteration is independent of the others, you simply
write a &lt;b&gt;parfor&lt;/b&gt; instead of &lt;b&gt;for&lt;/b&gt; and you're set.
&lt;/p&gt;

&lt;p&gt;
In Python, you have to prevent infinite, recursive function calls by
placing your code in the &lt;b&gt;&lt;span class="underline"&gt;&lt;span class="underline"&gt;main&lt;/span&gt;&lt;/span&gt;&lt;/b&gt; section of your script or by
placing the function in a different script and importing it. You also
have to be sure that Numpy and other Python modules that use BLAS
haven't reset the core affinity. What you gain over Matlab's
implementation is the power of using Python as a general programming
language with a lot of tools for scientific computing. This and the
multiprocessing module is free; you have to have an institute license
or pay for Matlab's &lt;a href="http://www.mathworks.com/products/parallel-computing/"&gt;Parallel Computing Toolbox&lt;/a&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>computing</category><category>python</category><guid>http://kmdouglass.github.io/posts/learning-pythons-multiprocessing-module.html</guid><pubDate>Mon, 29 Dec 2014 17:42:23 GMT</pubDate></item></channel></rss>